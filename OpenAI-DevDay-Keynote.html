<!DOCTYPE html>
<html lang="en"><head><title>OpenAI DevDay Keynote</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ü™¥ Quartz 4.0"/><meta property="og:title" content="OpenAI DevDay Keynote"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="OpenAI DevDay Keynote"/><meta name="twitter:description" content="www.youtube.com/watch Experimenting with the efficiency of the intellectual production process of a Japanese person understanding this 45-minute video in English ..."/><meta property="og:description" content="www.youtube.com/watch Experimenting with the efficiency of the intellectual production process of a Japanese person understanding this 45-minute video in English ..."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="www.youtube.com/watch Experimenting with the efficiency of the intellectual production process of a Japanese person understanding this 45-minute video in English ..."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/OpenAI-DevDay-Keynote"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/OpenAI-DevDay-Keynote"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="www.youtube.com/watch Experimenting with the efficiency of the intellectual production process of a Japanese person understanding this 45-minute video in English ..."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="OpenAI-DevDay-Keynote"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">ü™¥ Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href>OpenAI DevDay Keynote</a></div></nav><h1 class="article-title">OpenAI DevDay Keynote</h1><p show-comma="true" class="content-meta"><span>Nov 07, 2023</span><span>13 min read</span></p></div></div><article class="popover-hint"><p><a href="https://www.youtube.com/watch?v=U9mJuUkhUzk" class="external">https://www.youtube.com/watch?v=U9mJuUkhUzk<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
Experimenting with the efficiency of the intellectual production process of a Japanese person understanding this 45-minute video in English.</p>
<p>Copy and paste the YouTube Transcript.</p>
<ul>
<li>There are about 9,000 tokens.</li>
<li><a href="https://platform.openai.com/tokenizer" class="external">https://platform.openai.com/tokenizer<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
<ul>
<li><img src="https://gyazo.com/b5d904533e44b854764d20fdefe0d68d/thumb/1000" alt="image"/></li>
</ul>
</li>
</ul>
<p>Put in gpt-4-1106-preview in Playground</p>
<ul>
<li>max length was short in default, so I maxed it out, it was 4095.</li>
<li><a href="https://platform.openai.com/playground?mode=chat&amp;model=gpt-4-1106-preview" class="external">https://platform.openai.com/playground?mode=chat&amp;model=gpt-4-1106-preview<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
prompt</li>
</ul>
<pre><code>[SYSTEM] Pick important features from following speech transcript and return bullet lists.
[USER] ...
</code></pre>
<p><img src="https://gyazo.com/2d1e46d0ea5667d026c7093d85156b42/thumb/1000" alt="image"/></p>
<p>result
<img src="https://gyazo.com/f09160f596dd3ffd8949d3a3530aa1c8/thumb/1000" alt="image"/></p>
<p>result</p>
<pre><code>- OpenAI DevDay Introduction 
  - Sam Altman welcomed attendees to the first-ever OpenAI DevDay.
  - OpenAI's history and connection to San Francisco.
  - Progress over the past year was highlighted.

- ChatGPT and GPT-4 
  - ChatGPT started as a research preview and evolved with the launch of GPT-4.
  - GPT-4 remained the most capable model available.
  - Launched voice and vision capabilities for ChatGPT.
  - DALL-E 3 released as the most advanced image model.
  - ChatGPT Enterprise introduced for business with enhanced features.

- OpenAI Usage and Growth 
  - 2 million developers on OpenAI's API.
  - Over 92% of Fortune 500 companies use OpenAI products.
  - ChatGPT reached approximately 100 million weekly active users.

- OpenAI‚Äôs Direction and Goals 
  - Focus on usability and practical impact of AI products on users' lives.
  - GPT-4 Turbo announced addressing developer feedback with new features.

- GPT-4 Turbo New Features 
  - Expanded context length of up to 128,000 tokens.
  - Better response control with JSON Mode and reproducible outputs.
  - Improved world knowledge with updated knowledge cut-off to April 2023.
  - New modalities like DALL-E 3 and text-to-speech API.
  - Customization via fine-tuning, with a new custom models program.
  - Doubling tokens per minute for established GPT-4 customers.

- Pricing Announcements 
  - GPT-4 Turbo made more affordable with a significant price reduction.
  - Improved affordability expected to drive more innovation and use cases.

- Future Commitments and Partnerships 
  - Ongoing partnership with Microsoft and a commitment to AI safety discussed.
  - The future of AI and agents, gradual iterative deployment emphasized.

- Introduction of GPTs 
  - Customized versions of ChatGPT tailored for specific purposes announced.
  - GPTs allow sharing and discovering ways to use ChatGPT.
  - Users can program GPTs with language, enabling broad accessibility.
  - The GPT store to be launched for public sharing and revenue sharing.

- Assistants API 
  - New API provides persistent threads, retrieval, code interpreter, and function calling.
  - Facilitates building agent-like experiences in apps.

- Acknowledgments 
  - Sam Altman thanked the OpenAI team for their hard work.
  - OpenAI's mission highlighted to revolutionize technology and society through AI, empowering individuals and humanity.
</code></pre>
<p>DeepL</p>
<pre><code>- Introduction to OpenAI DevDay
  - Sam Altman welcomed participants to the first OpenAI DevDay.
  - OpenAI's history and connection to San Francisco.
  - Progress over the past year was highlighted.

- ChatGPT and GPT-4
  - ChatGPT began as a research preview and evolved with the launch of GPT-4.
  - The GPT-4 remained the most capable model.
  - Initiate audio and visual features of ChatGPT.
  - DALL-E 3 is presented as the latest image model.
  - ChatGPT Enterprise was enhanced and introduced for business use.

- Use and Growth of OpenAI
  - Two million developers use OpenAI's API.
  - More than 92% of Fortune 500 companies use OpenAI products.
  - ChatGPT reached approximately 100 million weekly active users.

- OpenAI Directions and Goals
  - Focus on the usability of AI products and their practical impact on users' lives.
  - GPT-4 Turbo announces that it will respond to developer feedback with new features.

- What's New in GPT-4 Turbo
  - Extended context length up to 128,000 tokens.
  - JSON mode and reproducible outputs provide better response control.
  - Updated knowledge cutoff in April 2023 improves global knowledge.
  - New modalities such as DALL-E 3 and speech synthesis APIs.
  - Customization with fine-tuning through a new custom model program.
  - For customers already using GPT-4, we will double the tokens per minute.

- Pricing Notice
  - GPT-4 Turbo is now more affordable with a significant price reduction.
  - With greater affordability, innovation and use cases are expected to expand.

- Future commitments and partnerships
  - Discussed ongoing partnership with Microsoft and their commitment to AI safety.
  - The future potential of AI and agents and gradual iterative development was emphasized.

- Introduction of GPT
  - Presented a customized version of ChatGPT for specific purposes.
  - GPT can share and discover how to use ChatGPT.
  - Users can program GPT in their language, allowing for a wide range of accessibility.
  - Open a GPT store for public access and revenue sharing.

- Assistant API
  - The new API provides persistent threads, search, code interpreter, and function calls.
  - Facilitates building an agent-like experience with the app.

- thanks
  - Sam Altman thanked the OpenAI team for their efforts.
  - He emphasized that OpenAI's mission is to empower individuals and humanity by revolutionizing technology and society through AI.
</code></pre>
<p>Let‚Äôs delve into the areas of interest.
prompt</p>
<pre><code>I'm interested in Assistants API. Explain it in detail.
</code></pre>
<p>result</p>
<pre><code>The Assistants API is a new offering from OpenAI announced at the DevDay event. Here's an in-depth look at what it entails:

- **Persistent Threads**: This feature allows developers to create a continuous conversation thread for each user interacting with the assistant. Unlike the traditional approach, where you need to resend the entire conversation history with each API call, persistent threads manage the state of the conversation and context for you. This simplifies the development process by allowing a continuous dialogue with the AI without having to manage context windows or the serialization of messages.

- **Retrieval**: Assistants API now has the capability to parse and understand external documents. This feature enables the AI to access additional knowledge beyond the current user messages by ingesting long-form documents or databases. This is useful when the AI needs to reference information not contained in the prompt or its own knowledge base.

- **Code Interpreter**: A feature that expands the capabilities of the AI to write, execute, and even generate code during conversation. This allows developers to create assistants that can perform more complex tasks such as data analysis, calculations, and code generation in real-time, akin to having a Python interpreter right within the chat interface.

- **Function Calling**: The Assistants API enhances function calling abilities by ensuring JSON-valid output and enabling the calling of multiple functions simultaneously. This greatly improves the potential for developers to integrate the AI with APIs and third-party services, allowing for a range of actions and interactions within the application.

- **Multimodal Capabilities**: The Assistants API incorporates OpenAI's new modalities, such as DALL-E 3 for image generation and a new text-to-speech API for generating natural-sounding audio. This integration enables developers to build richer, multimodal user experiences.

- **Developer Dashboard**: The API offers a dashboard where developers can see the steps the tools are taking, which includes executing functions with specified parameters and managing uploaded documents. This feature provides transparency and control, allowing developers to troubleshoot and optimize their assistant's behavior.

- **Simplification and Efficiency**: The Assistants API is designed to streamline the process of building advanced AI assistants. It removes the complexity involved in managing conversation states, chunking algorithm setup, and custom backend systems for knowledge retrieval. This means developers can build sophisticated assistive agents with less effort, lower maintenance, and reduced development times.

- **Integration with Apps**: The Assistants API can be integrated into applications to provide users with an interactive AI that can manage conversations, invoke functionalities of the app, and even take real-world actions based on user requests.

As demonstrated in the event, the Assistants API can be put to practical use in a travel app where it answers user queries about destinations, retrieves book flight details or accommodation reservations, and even performs financial calculations for shared expenses.

The Assistants API is a significant step towards creating AI-enhanced user experiences that are more engaging, intuitive, and powerful. It is intended to help developers create not just chat interfaces, but intelligent agents capable of acting on behalf of the user, ultimately leading to the future of AI agents as envisioned by OpenAI.
</code></pre>
<p>DeepL</p>
<pre><code>Assistants API is a new OpenAI service announced at the DevDay event. Here is a closer look at what it entails:
 
 - **Persistent Threads**: This feature allows developers to create a persistent conversation thread for each user interacting with the assistant; unlike the traditional approach that requires resubmitting the entire conversation history with each API call, persistent threads can be used to manage the conversation state and context. This simplifies the development process by allowing continuous interaction with the AI without having to manage context windows and message serialization.
 
 - Search**: The Assistant API now has the ability to parse and understand external documents. This feature allows the AI to access additional knowledge beyond the current user message by importing long documents and databases. This is useful when the AI needs to reference information not included in prompts or its own knowledge base.
 
 - Code Interpreter**: a feature that extends the AI's ability to write, execute, and generate code during conversations. This allows developers to create assistants that can perform more complex tasks such as data analysis, computation, and code generation in real time.
 
 - Function Call**: The Assistants API enhances function calling capabilities by guaranteeing JSON-valid output and allowing multiple function calls at the same time. This greatly increases the possibility for developers to integrate AI with APIs and third-party services, enabling a variety of actions and interactions within an application.
 
 - **Multi-modal capabilities**: The Assistant API incorporates new OpenAI modalities such as DALL-E 3 for image generation and a new speech synthesis API for natural voice generation. This integration allows developers to build richer, multimodal user experiences.
 
 - Developer Dashboard**: The API provides a dashboard that allows developers to see the steps the tool performs, such as executing a function with specified parameters or managing uploaded documents. This feature provides transparency and control, allowing developers to troubleshoot and optimize the behavior of the assistant.
 
 - Simplify and Streamline**: The Assistants API is designed to streamline the process of building advanced AI assistants. It removes the complexity involved in managing conversational state, setting up chunking algorithms, and custom back-end systems for knowledge retrieval. This means that developers can build sophisticated assistive agents with less effort, less maintenance, and shorter development times.
 
 - **Integration with Apps**: By integrating the Assistants API into your application, you can provide users with an interactive AI that can manage conversations, invoke app features, and even take actual actions based on user requests.
 
 As demonstrated at the event, the Assistants API can be put to practical use in travel apps, answering user inquiries about destinations, retrieving booked flight details and lodging reservations, and even performing financial calculations for shared expenses.
 
 The Assistants API is an important step toward creating a more engaging, intuitive, and powerful AI-enhanced user experience. The API is intended to enable developers to create not just chat interfaces, but intelligent agents that can act on behalf of users, ultimately leading to the future of AI agents as envisioned by OpenAI.
</code></pre>
<p>Now, with this in mind, let‚Äôs see the video in action</p>
<ul>
<li>
<p>I know what it‚Äôs about, so I‚Äôll listen at 1.25x.</p>
</li>
<li>
<p>The abstraction of ‚Äúthreads and messages.‚Äù</p>
<ul>
<li>Server-side persistence
<ul>
<li>Do they digest only the most recent ones on their own, or do they<a href="./MemoChat" class="internal" data-slug="MemoChat">MemoChat</a>ÁöÑ„Å™‰ªïÁµÑ„Åø„ÅßÊ§úÁ¥¢„Åô„Çã„ÅÆ„Åã„ÄÅ„Å©„Å£„Å°„Åã„Å™<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>
<ul>
<li>I hope it‚Äôs the latter.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Guaranteed output in JSON format ‚Äúwithout additional latency</p>
<ul>
<li>You‚Äôve applied a robust format guarantee fine tuning, and the probability of failure must be so small that it‚Äôs negligible.<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></li>
</ul>
</li>
<li>
<p>The search demo doesn‚Äôt really fit my needs (because it‚Äôs a demo that is designed to be popular with the general public).<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></p>
</li>
<li>
<p>Providing a startful API with persistent storage has drastically reduced implementation costs on the part of third-party developers.</p>
<ul>
<li>I no longer have to think about chunking or context width.
<ul>
<li>I wonder if the contents of this persistent storage can be retrieved later, if not, GDPR will be pissed off, so maybe they can.<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>
<ul>
<li>Oooooh, I can see the list of threads on the developer dashboard.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>With Code Interpreter integrated, processes that are better written in Python than in natural language can be written in Python.</p>
<ul>
<li>I looked at the available formats and they include C++ and Java‚Ä¶<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></li>
</ul>
</li>
<li>
<p>The addition of audio input and output allows for impressive demonstrations.</p>
<ul>
<li>I‚Äôm sure we‚Äôll be seeing more and more demonstrations of this in the future, and it will help to increase the ‚ÄúOpenAI is awesome‚Äù atmosphere in the world.<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></li>
</ul>
</li>
</ul>
<h2 id="try-the-assistants-api">Try the Assistants API<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#try-the-assistants-api" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>.
Save PDF of my book <a href="./The-Intellectual-Production-of-Engineers" class="internal alias" data-slug="The-Intellectual-Production-of-Engineers">The Intellectual Production of Engineers</a> with Upload, Retrieval turned on</p>
<ul>
<li>The reason it takes a little longer is probably because it is chunking and building a vector index.
<img src="https://gyazo.com/04b3f5bca54454f8ebbe8e72aaf79b30/thumb/1000" alt="image"/>
I‚Äôm not sure if you referenced the PDF or not, so I‚Äôll try to make an explicit reference to it.
<img src="https://gyazo.com/3f13cafc2bf284f161243604bf47a09e/thumb/1000" alt="image"/>
Properly referenced.</li>
<li>You can see where the reference is made.
<ul>
<li><img src="https://gyazo.com/9035a9053d0ac580955711bc071fe7d9/thumb/1000" alt="image"/>
<ul>
<li>Table of Contents.
I‚Äôll make a more explicit request.</li>
</ul>
</li>
</ul>
</li>
<li><img src="https://gyazo.com/ca223615727e5a649af21ba49e830412/thumb/1000" alt="image"/></li>
<li>You make it sound so plausible.</li>
</ul>
<p>Another question</p>
<ul>
<li><img src="https://gyazo.com/6fe155ea2ad2e3b5b1cd74fa07ae8d65/thumb/1000" alt="image"/></li>
<li>The link in the source display is probably garbled and cannot be seen in the UI: `<a href="./9‚Ä†source" class="internal alias" data-slug="9‚Ä†source">9‚Ä†source</a>‚Äô.
<ul>
<li>The log itself doesn‚Äôt come with any information about the search results.</li>
<li>If the link isn‚Äôt broken, you can check the source from the UI, so there should be an API to get that.
<ul>
<li>Ah, so the information is originally given to the message in the form of annotations?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>impressions</p>
<ul>
<li>It‚Äôs super easy to create a permanent assistant just by throwing a PDF of a book at them and have them respond based on the book‚Äôs content at any time.
<ul>
<li>The ability to buy books in PDF format will become a customer value in the form of ‚Äúcan I get an AI to read it?‚Äù</li>
</ul>
</li>
<li>For my personal research purposes, I want to tweak the details, so it‚Äôs a bit useless.
<ul>
<li>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1721800710134915476/quick_promote_web/intro" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> OpenAI DevDay reminded me of the days when Microsoft released Visual Basic and Visual C++, and the variety of ‚ÄúWindows apps‚Äù that were being created with them. I think that OpenAI has created a situation where the time cost for engineers to create ‚ÄúAI apps‚Äù is much cheaper.</p>
</blockquote>
</li>
<li>Positioning WordPress as a way to create websites.</li>
</ul>
</li>
</ul>
<p>I summarized the SLIDE.
- <a href="./Programming-Education-in-the-Age-of-Generative-AI-Toward-the-Joy-of-Creating-and-Learning" class="internal alias" data-slug="Programming-Education-in-the-Age-of-Generative-AI-Toward-the-Joy-of-Creating-and-Learning">Programming Education in the Age of Generative AI Toward the Joy of Creating and Learning</a></p>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1721857526990586203/quick_promote_web/intro" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Put my book ‚ÄúThe Intellectual Production of Engineers‚Äù into OpenAI Assistants API and ask a question. This is exactly what I‚Äôm talking about, the ‚Äúefficiency of how to read books‚Äù feeling.
<img src="https://pbs.twimg.com/media/F-VEHiGakAEioDR?format=jpg&amp;name=medium#.png" alt="image"/></p>
</blockquote>
<hr/>
<p>This page is auto-translated from [/nishio/OpenAI DevDay Keynote](<a href="https://scrapbox.io/nishio/OpenAI" class="external">https://scrapbox.io/nishio/OpenAI<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> DevDay Keynote) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I‚Äôm very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./OpenAI-DevDay" class="internal">OpenAI DevDay</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> ¬© 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>