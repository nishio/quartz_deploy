<!DOCTYPE html>
<html lang="en"><head><title>BERTopic: Neural topic modeling with a class-based TF-IDF</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ü™¥ Quartz 4.0"/><meta property="og:title" content="BERTopic: Neural topic modeling with a class-based TF-IDF"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="BERTopic: Neural topic modeling with a class-based TF-IDF"/><meta name="twitter:description" content="2203.05794 BERTopic: Neural topic modeling with a class-based TF-IDF procedure BERTopic: Neural topic modeling with a class-based TF-IDF (2022) Summary: /What is a class-based ..."/><meta property="og:description" content="2203.05794 BERTopic: Neural topic modeling with a class-based TF-IDF procedure BERTopic: Neural topic modeling with a class-based TF-IDF (2022) Summary: /What is a class-based ..."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="2203.05794 BERTopic: Neural topic modeling with a class-based TF-IDF procedure BERTopic: Neural topic modeling with a class-based TF-IDF (2022) Summary: /What is a class-based ..."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/BERTopic:-Neural-topic-modeling-with-a-class-based-TF-IDF"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/BERTopic:-Neural-topic-modeling-with-a-class-based-TF-IDF"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="2203.05794 BERTopic: Neural topic modeling with a class-based TF-IDF procedure BERTopic: Neural topic modeling with a class-based TF-IDF (2022) Summary: /What is a class-based ..."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="BERTopic:-Neural-topic-modeling-with-a-class-based-TF-IDF"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">ü™¥ Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href>BERTopic: Neural topic modeling with a class-based TF-IDF</a></div></nav><h1 class="article-title">BERTopic: Neural topic modeling with a class-based TF-IDF</h1><p show-comma="true" class="content-meta"><span>Jun 12, 2024</span><span>4 min read</span></p></div></div><article class="popover-hint"><p><a href="https://arxiv.org/abs/2203.05794" class="external">2203.05794 BERTopic: Neural topic modeling with a class-based TF-IDF procedure<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
<a href="./BERTopic" class="internal" data-slug="BERTopic">BERTopic</a>: Neural <a href="./topic-model" class="internal alias" data-slug="topic-model">topic model</a>ing with a <a href="./class-based-TF-IDF" class="internal alias" data-slug="class-based-TF-IDF">class-based TF-IDF</a> (2022)</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>Summary: /What is a class-based TF-IDF? /What are the advantages over LDA and other methods? /What is HDBSCAN used for? What is /UMAP used for? By what metric do you claim this method is superior? /What is CTM? /The above exchange should be a summarized exchange to be saved in my notebook, while preserving my question text.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>BERTopic is a new topic model using pre-trained language models and class-based TF-IDF. Compared to traditional LDA and other methods, it has the following advantages</p>
<ul>
<li>Enables topic modeling that takes into account the context of words by leveraging language models</li>
<li>Separate document clustering and topic representation generation for flexible architecture</li>
<li>Easily applied to dynamic topic modeling</li>
<li>Stable performance in different language models</li>
</ul>
<p>In BERTopic, documents are first embedded into high-dimensional vectors in a language model. Next, it extracts topics by dimensionality reduction using UMAP and clustering using HDBSCAN. Finally, a class-based TF-IDF is used to generate topic representations.</p>
<ul>
<li><a href="./Class-Based-TF-IDF" class="internal alias" data-slug="Class-Based-TF-IDF">Class-Based TF-IDF</a> groups documents by topic and calculates the importance of words within each group. This allows more direct extraction of words that characterize a topic.</li>
</ul>
<p><a href="./UMAP" class="internal" data-slug="UMAP">UMAP</a> is a nonlinear dimensionality reduction method that preserves the local and global structure of high-dimensional data while efficiently embedding it in a low-dimensional space. <a href="./HDBSCAN" class="internal" data-slug="HDBSCAN">HDBSCAN</a> is a density-based clustering method that provides noise-robust clustering without specifying the number of clusters.</p>
<p>BERTopic shows excellent performance on the topic consistency and topic diversity measures, and has an advantage in computational efficiency compared to other state-of-the-art methods such as CTM. However, challenges remain, such as the inability to directly model that a single document has multiple topics.</p>
<p><a href="./CTM" class="internal" data-slug="CTM">CTM</a> is a state-of-the-art topic model that, like BERTopic, leverages language models. It takes a <a href="./VAE" class="internal" data-slug="VAE">VAE</a>-based approach and learns topics end-to-end by integrating contextual information and frequency of occurrence of words. It shows excellent results in topic quality, but suffers from high computational cost.</p>
<ul>
<li><a href="./Class-Based-TF-IDF" class="internal alias" data-slug="Class-Based-TF-IDF">Class-Based TF-IDF</a></li>
</ul>
<hr/>
<p>The evaluation indicators are oversimplified.</p>
<img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>
The superiority of BERTopic is evaluated and claimed mainly by the following two indicators
<ol>
<li>topic coherence
Topic coherence is a measure of the degree to which the words comprising a topic are semantically coherent. Specifically, it is calculated based on semantic similarity and co-occurrence probability between words within a topic.</li>
</ol>
<p>The paper uses a measure of topic consistency called Normalized Pointwise Mutual Information (NPMI), which is calculated from the co-occurrence probability of word pairs within a topic and the occurrence probability of each word.</p>
<p>Experimental results show that BERTopic achieves higher NPMI scores than conventional methods such as LDA and NMF. This suggests that BERTopic can generate semantically coherent topics.</p>
<ol start="2">
<li>topic diversity
Topic diversity is a measure of the degree of overlap between generated topics. The less overlap of words between topics, the higher the topic diversity is considered.</li>
</ol>
<p>The paper defines topic diversity as the percentage of unique words in all topics; closer to 0 indicates more topic overlap and closer to 1 indicates more topic diversity.</p>
<p>Experimental results report that BERTopic achieves relatively high topic diversity, but not as high as CTM. However, BERTopic has shown greater performance stability with language model selection than CTM.</p>
<p>In addition to these metrics, the paper discusses the computational efficiency of BERTopic, which has been shown to be significantly faster than CTM and can process large data sets in realistic time.</p>
<p>As described above, BERTopic shows superior performance compared to conventional topic models in terms of topic consistency, topic diversity, and computational efficiency. It should be noted, however, that as the authors acknowledge, these automatic evaluation metrics are only approximations, and subjective evaluation by actual users is also important.</p>
<hr/>
<p><a href="https://maartengr.github.io/BERTopic/index.html#modularity" class="external">BERTopic<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
<a href="./CountVectorizer" class="internal" data-slug="CountVectorizer">CountVectorizer</a></p>
<p><a href="./Clustering-Topics" class="internal alias" data-slug="Clustering-Topics">Clustering Topics</a></p>
<hr/>
<p>This page is auto-translated from [/nishio/BERTopic: Neural topic modeling with a class-based TF-IDF](<a href="https://scrapbox.io/nishio/BERTopic" class="external">https://scrapbox.io/nishio/BERTopic<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>: Neural topic modeling with a class-based TF-IDF) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I‚Äôm very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> ¬© 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>