<!DOCTYPE html>
<html lang="en"><head><title>Key phrase extraction 2020-08</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="🪴 Quartz 4.0"/><meta property="og:title" content="Key phrase extraction 2020-08"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Key phrase extraction 2020-08"/><meta name="twitter:description" content="Cybozu Labs Machine Learning Study Group keyphrase extraction Extract several short strings of less than one sentence from an input string longer than one sentence This time around ..."/><meta property="og:description" content="Cybozu Labs Machine Learning Study Group keyphrase extraction Extract several short strings of less than one sentence from an input string longer than one sentence This time around ..."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="Cybozu Labs Machine Learning Study Group keyphrase extraction Extract several short strings of less than one sentence from an input string longer than one sentence This time around ..."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/Key-phrase-extraction-2020-08"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/Key-phrase-extraction-2020-08"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="Cybozu Labs Machine Learning Study Group keyphrase extraction Extract several short strings of less than one sentence from an input string longer than one sentence This time around ..."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Key-phrase-extraction-2020-08"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">🪴 Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Key phrase extraction 2020-08</a></div></nav><h1 class="article-title">Key phrase extraction 2020-08</h1><p show-comma="true" class="content-meta"><span>Aug 14, 2020</span><span>7 min read</span></p></div></div><article class="popover-hint"><p>Cybozu Labs Machine Learning Study Group</p>
<ul>
<li><a href="./keyphrase-extraction" class="internal alias" data-slug="keyphrase-extraction">keyphrase extraction</a></li>
<li>Extract several short strings of less than one sentence from an input string longer than one sentence</li>
<li>This time around.
<ul>
<li>Review (~<a href="./TextRank" class="internal" data-slug="TextRank">TextRank</a>)</li>
<li><a href="./RAKE" class="internal" data-slug="RAKE">RAKE</a>
<ul>
<li><a href="./concentration-(of-one's-attention)" class="internal alias" data-slug="concentration-(of-one's-attention)">concentration (of one’s attention)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Word Frequency Approach</p>
<ul>
<li>Carve input into words</li>
<li>Count the number of occurrences of each word.</li>
<li>Score the “number of times”.
<ul>
<li>This is called TF (Term Frequency)</li>
</ul>
</li>
<li>Showing the highest score</li>
</ul>
<p>problem</p>
<ul>
<li>Frequent occurrence of words like “of” and “wo.”</li>
<li>This is a frequent occurrence in any text.</li>
<li>I want to lower my score.</li>
</ul>
<p><a href="./TF-IDF" class="internal" data-slug="TF-IDF">TF-IDF</a></p>
<ul>
<li>Count the number of documents in which the word x appears
<ul>
<li>Large DF words are “common” words</li>
<li>This is called <a href="./DF" class="internal" data-slug="DF">DF</a>(Document Frequency)</li>
<li>So, the larger the DF, the smaller the score, which is TF-IDF</li>
</ul>
</li>
<li>(aside)
<ul>
<li>It is interesting to see a characteristic distribution for key phrases (<a href="./concentration-(of-one's-attention)" class="internal alias" data-slug="concentration-(of-one's-attention)">concentration (of one’s attention)</a>) when plotted on two axes with DF2, “the number of documents in which the word x appears two or more times.</li>
<li>I’d take a log, but there doesn’t seem to be much theoretical support for it.</li>
<li>Affected by average number of words in “document,” etc.
<ul>
<li>If you use books, is one document a “book” or a “page”?</li>
<li>If it’s groupware, is it one post, one thread, one space?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>general managers’ committee issue</p>
<ul>
<li>The term “General Manager’s Meeting” refers to a specific recurring event throughout this in Cybozu.</li>
<li>But when chopped into words, they are divided into “book,” “director,” and “association.”
<ul>
<li>It gets mixed up with “book” meaning “book” and “meeting” meaning “meeting” of other events.</li>
<li>Even if the word “director” was used with high frequency, it is difficult for a human being to think from it that you are talking about the General Manager’s Association.</li>
</ul>
</li>
<li>If it is to be shown to humans, it is necessary to extract “sequences of multiple words” as key phrases</li>
</ul>
<p><a href="./2004" class="internal alias" data-slug="2004">[TextRank]</a></p>
<ul>
<li>“TextRank: Bringing Order into Texts”</li>
<li>If you chop them into words and treat them discretely, you lose information about word order, which is not good.</li>
<li>Then, a graph is created with words as vertices and adjacencies as edges, which is multiplied by eigenvalue analysis to obtain a score for each word.
<ul>
<li>Inspired by Google’s PageRank, hence the name TextRank.</li>
</ul>
</li>
<li>Words in the top 1/3 of the score are concatenated if they occur consecutively in the source text</li>
<li>problem
<ul>
<li>Q: Wouldn’t high frequency words score higher?</li>
<li>A: Yes, so TextRank uses only nouns and adjectives (noun phrase approach).</li>
</ul>
</li>
</ul>
<p>Problems with the noun phrase approach</p>
<ul>
<li>Narrowing down the candidates too much
<ul>
<li>Neither “intellectual production techniques of engineers” nor “100 people, 100 different ways of working” can be key phrases.</li>
<li>The “Lean Startup” is carved in middle black.</li>
<li>Analysis of data from users who frequently use Scrapbox showed that 10% to 30% of key phrases contained non-noun adjectives <span>→</span> <a href="./Scrapbox-Statistics-2019-2" class="internal alias" data-slug="Scrapbox-Statistics-2019-2">Scrapbox Statistics 2019-2</a>.</li>
</ul>
</li>
</ul>
<p><a href="./2010" class="internal alias" data-slug="2010">[RAKE]</a></p>
<ul>
<li>
<p>Rapid Automatic Keyword Extraction</p>
</li>
<li>
<p><a href="https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents" class="external">Automatic Keyword Extraction from Individual Documents<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</li>
<li>
<p>Same issues as Nishio.</p>
<ul>
<li>I want to take out “axis of evil” as a key phrase.</li>
</ul>
</li>
<li>
<p>structure</p>
<ul>
<li>1: First, divide by the words in the stop list</li>
<li>2: If key phrases appear in the same order, they are combined, including the words in between.</li>
<li><img src="https://gyazo.com/f4483bde4be44d3391ad3d33d60e1105/thumb/1000" alt="image"/></li>
</ul>
</li>
<li>
<p>The key is how to make a stop list.</p>
<ul>
<li>TextRank’s noun phrase approach is equivalent to putting all but noun adjectives in the stop list</li>
</ul>
</li>
<li>
<p><a href="./RAKE-stop-list-generation" class="internal alias" data-slug="RAKE-stop-list-generation">RAKE stop list generation</a></p>
</li>
<li>
<p>The paper tries two patterns six different ways.</p>
<ul>
<li>Pattern TF:.
<ul>
<li>The idea that words that occur frequently are stop targets.</li>
<li>Use a lot of word DFs.</li>
</ul>
</li>
<li>Pattern KA:.
<ul>
<li>The idea is that words that appear next to key phrases and do not appear easily in key phrases are stop targets.</li>
<li>If the number of occurrences in a key phrase is greater than the number of occurrences next to the key phrase, exclude it from the stop list</li>
</ul>
</li>
</ul>
</li>
<li>
<p>result</p>
<ul>
<li>KA is good all around.</li>
<li>In TF, increasing the number of stoplists decreases performance, in KA it increases it.</li>
<li>With KA, “words that also occur frequently in key phrases” don’t make the stop list, so they can be increased.</li>
<li><img src="https://gyazo.com/ff40bc46f5d69f64b8cd6577a5f215e2/thumb/1000" alt="image"/></li>
</ul>
</li>
</ul>
<p>benchmark</p>
<ul>
<li>Speed is significantly faster than TextRank
<ul>
<li>TextRank is heavy on solving large matrix eigenvalue problems.</li>
</ul>
</li>
<li>Accuracy is best in both F value and percentage of fit.
<ul>
<li>The conformance rate is the percentage of key phrases that the system determines to be key phrases that are actually key phrases.</li>
<li>TextRank methods have evolved in various ways since then: <a href="./PositionRank" class="internal" data-slug="PositionRank">PositionRank</a>, <a href="./EmbedRank" class="internal" data-slug="EmbedRank">EmbedRank</a>, and so on.</li>
</ul>
</li>
</ul>
<p>supplementary examination</p>
<ul>
<li>Assume that the key phrase is the range enclosed by the Wikipedia link notation <code>[[ ]]</code>.</li>
<li>Generate stop list with 1000/2000 pages</li>
<li>Key phrase extraction against 1000 other pages</li>
<li>Example: <a href="https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%91%E3%82%B5%E3%83%B3%E3%83%89" class="external">ampersand<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
<ul>
<li>INPUT <code>ampersand (&amp;amp;) is a symbol for the juxtaposition of the particles &quot;...and...&quot;. It is a ligature of the Latin &quot;et&quot; and is easily recognized in the Trebuchet MS font as &lt;FILE>. ampersa, &quot;and per se and&quot;, means &quot;and [the symbol which] by itself [is] and&quot;. ... </code></li>
<li>EXPECTED <code>['symbol', 'Latin', 'ligature', 'Trebuchet MS', ... </code></li>
<li>OUTPUT <code>['symbol which] by itself [is] and', 'ampersand (&amp;amp;, English name', 'and per se and', 'Trebuchet MS font', 'and [', 'ampersand', 'parallel particle', 'ampersa', 'Latin ', 'FILE', 'understand', 'symbol', 'display', 'meaning', 'ligature', 'et', ... </code></li>
<li><code>Precision: 0.208, Recall: 0.808, F-measure: 0.331</code></li>
</ul>
</li>
<li>Precision 0.32+-0.30 for 1000 pages
<ul>
<li>Roughly similar results to the paper were reproduced.</li>
<li>Large standard deviation
<ul>
<li>It may be due to the fact that the abstracts of the papers are generally of similar length, whereas the random pages on Wikipedia are of varying lengths.</li>
</ul>
</li>
<li>small talk
<ul>
<li>I’m taking the top 1/3 of the paper.</li>
<li>Normally, Precision goes down as you increase it.</li>
<li>In this experiment, it went up the other way.</li>
<li>High scoring key phrases have a high probability of not being correct.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Comparison</p>
<ul>
<li>TextRank
<ul>
<li>Stop list: non-noun adjectives</li>
<li>Combining: if high scoring adjacent to each other</li>
</ul>
</li>
<li>RAKE
<ul>
<li>Stop list: compare inside and adjacent to key phrases</li>
<li>Combining: if they appear in the same order</li>
</ul>
</li>
</ul>
<p>Stop List Considerations</p>
<ul>
<li>Stop list can be regarded as a “string <span>→</span> 0/1” function</li>
<li>What is “chopping at the stop word?”
<ul>
<li><img src="https://gyazo.com/cdaa7d86db568a4ea3bf72d6e90a31b6/thumb/1000" alt="image"/></li>
<li>The red part is 1-p and then “the product is 1.”</li>
<li>Consistent with the comparison of “number of occurrences within a keyword” and “number of occurrences next to a keyword.”</li>
</ul>
</li>
<li>Is 0/1 sufficient?
<ul>
<li>’s” and so on, in, but also adjacent to.</li>
<li>Unknown words are not on the stop list.</li>
<li>You don’t want to have “tokens that shouldn’t be in keywords” that appear infrequently.</li>
</ul>
</li>
<li>For example, if a URL is mixed in with the input
:</li>
</ul>
<pre><code>f noun,general,*,*,*,*,*
3 noun,number,*,*,*,*,*
b noun,general,*,*,*,*,*
1 noun,number,*,*,*,*,*
af noun,general,*,*,*,*,*
2 noun,number,*,*,*,*,*
daee noun,general,*,*,*,*,*
8 noun,number,*,*,*,*,*
e noun,general,*,*,*,*,*
942 noun,number,*,*,*,*,*
b noun,general,*,*,*,*,*
49 noun,number,*,*,*,*,*
adbb noun,general,*,*,*,*,*
2 noun,number,*,*,*,*,*
e noun,general,*,*,*,*,*
40 noun,number,*,*,*,*,*
f noun,general,*,*,*,*,*
0 noun,number,*,*,*,*,*
c noun,general,*,*,*,*,*
6746 noun,number,*,*,*,*,*
f noun, proper noun, organization,*,*,*,*
</code></pre>
<p>Proposal to make it a stochastic model</p>
<ul>
<li>future work</li>
<li><a href="./CRF" class="internal" data-slug="CRF">CRF</a>
<ul>
<li>Commonly used in morphological analysis itself and other series labeling</li>
</ul>
</li>
<li>“Two or more occurrences of a key phrase sequence” is a global feature not used in CRFs, etc.
<ul>
<li>How do I make this work?</li>
</ul>
</li>
</ul>
<p>Regarding keyphrase binding</p>
<ul>
<li>Now they don’t care what kind or how many tokens they have, they’re combining them anyway.</li>
<li><code>'Make a presentation \u3000\u3000↓ \u3000 (immediately after the action'</code>)
<ul>
<li>They are combined because they appear multiple times, but I don’t want full-width spaces in the key phrase.</li>
<li>To begin with, the newlines are gone at the MeCab stage, but shouldn’t the newlines be tokens that never enter the keyphrase?</li>
</ul>
</li>
<li>of tokens inserted between them “probability of appearing in a key phrase.”</li>
</ul>
<hr/>
<p>This page is auto-translated from <a href="https://scrapbox.io/nishio/%E3%82%AD%E3%83%BC%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E6%8A%BD%E5%87%BA2020-08" class="external">/nishio/キーフレーズ抽出2020-08<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I’m very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> © 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>