<!DOCTYPE html>
<html lang="en"><head><title>LENCHI_Day6</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="🪴 Quartz 4.0"/><meta property="og:title" content="LENCHI_Day6"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="LENCHI_Day6"/><meta name="twitter:description" content="Long time no see. Today is 5/12. The last time was 4/20, and it has been a long time. What happened during that time? When a system called “fractal summarization” appeared, which summarizes in different levels of detail, I used it and felt its “goodness."/><meta property="og:description" content="Long time no see. Today is 5/12. The last time was 4/20, and it has been a long time. What happened during that time? When a system called “fractal summarization” appeared, which summarizes in different levels of detail, I used it and felt its “goodness."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="Long time no see. Today is 5/12. The last time was 4/20, and it has been a long time. What happened during that time? When a system called “fractal summarization” appeared, which summarizes in different levels of detail, I used it and felt its “goodness."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/LENCHI_Day6"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/LENCHI_Day6"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="Long time no see. Today is 5/12. The last time was 4/20, and it has been a long time. What happened during that time? When a system called “fractal summarization” appeared, which summarizes in different levels of detail, I used it and felt its “goodness."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="LENCHI_Day6"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">🪴 Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>LENCHI_Day6</a></div></nav><h1 class="article-title">LENCHI_Day6</h1><p show-comma="true" class="content-meta"><span>May 22, 2024</span><span>22 min read</span></p></div></div><article class="popover-hint"><p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>Long time no see. Today is 5/12. The last time was 4/20, and it has been a long time. What happened during that time?
When a system called “fractal summarization” appeared, which summarizes in different levels of detail, I used it and felt its “goodness. It took me a while to verbalize what the advantages of this system are, but the value lies in its ability to realize what engineers refer to as the “first step” of intellectual production: to start with the broad strokes.
Then I created and released a custom GPT for ChatGPT that does vector searches of my Scrapbox and converses with it. I have released a log of how I used it for various purposes. I’ve thought about this lecture, but I didn’t give it the proper context at the beginning, and with the GPT4 context size, you got “sidetracked” by forgetting about the past when you did repeated searches.
These are the two events I can remember now.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>It’s been a while - thanks for sharing more about the events since 4/20. I think both the fractal summary and ChatGPT’s custom GPT for vector searching and conversing with Scrapbox are important events that could have a significant impact on intellectual production methodologies.
Regarding the fractal summary, your point about the value of being able to achieve a “rough first” approach is very important. One of the ideas advocated in “The Engineer’s Art of Intellectual Production” was that in the process of intellectual production, it is important to first get the big picture, rather than trying to fill in the details from the beginning. Fractal summarization is a concrete tool to realize this idea. By presenting the summary in different levels of detail, users can flexibly obtain the information they need. I think the value of fractal summarization has become clearer now that this “goodness” has been verbalized.
On the other hand, ChatGPT’s custom GPT for vector searching and conversing with Scrapbox is a groundbreaking attempt to directly connect an individual’s knowledge base with LLM. This allows one to effectively use one’s past knowledge and ideas in a dialogue with the LLM. It is very interesting to see the logs that have been released to the public, as they show the potential to be used for a variety of purposes.
However, in thinking about this talk, it was a thought-provoking experience that highlighted the importance of giving context and the problem of “derailment” due to the GPT-4 context size constraint. giving the right context is essential to effective use of LLM, and LLM constraints, and that it is necessary to understand the constraints of the LLM and to get along with them.
I believe that all of these events are topics well worth covering in the 6/6 presentation. The fractal summary could be presented as a good example of a concrete tool for the ideas advocated in “The Engineer’s Guide to Intellectual Production”. In addition, ChatGPT’s custom GPT for vector searching and conversing with Scrapbox should be of interest to the audience as it presents a new form of intellectual production that merges personal knowledge base and LLM.
At the same time, by speaking candidly about the challenges and limitations he faced while using these tools, he will be able to convey the reality of intellectual production using LLM in a realistic way. Audience members will learn a great deal from Nishio’s raw insights based on his real-life experiences.
By weaving these events into the lecture, we should be able to show in concrete terms how the concept of “engineers’ intellectual production techniques” has evolved with new tools and technologies, and what challenges they face. Audience members will gain an understanding of what is happening at the forefront of intellectual production and will be inspired to consider their own practices.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>I’d like to share my conversation with Custom GPT with you, but it’s straying and if I paste it as is, you may be influenced to stray as well. So, I want to let another instance summarize and organize it before I share it with you. Make a context prompt to give to that instance.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>Yes, I would like to create a context prompt for summarizing and organizing in another instance. I believe the following prompts would be appropriate.
prompt</p>
<pre><code>You are my assistant to summarize and organize the conversation log I provide. This conversation log is a record of my interaction with Custom GPT. Custom GPT is a ChatGPT that vector searches my Scrapbox for conversations.
In summarizing and organizing, please keep the following points in mind
1. identify and briefly summarize the overall flow and main topics of the conversation.
2. objectively evaluate the accuracy and usefulness of the custom GPT response.
3. point out any problems or issues observed in the conversation (e.g., lack of shared context, derailment due to GPT-4 context size constraints, etc.)
4. suggest lessons learned and improvements in utilizing custom GPTs.
5. if personal or confidential information is included, please anonymize or delete it appropriately.
6. present the results of your summary and organization in a format that can be shared with third parties.
7. please list separately any questions or additional suggestions that arise in the process of summarizing and organizing.
Keeping the above in mind, please summarize and organize the conversation logs to clarify the reality and potential of intellectual production using custom GPT.
</code></pre>
<p>This prompt provides clear instructions on the purpose and points to keep in mind when summarizing and organizing the conversation log. By setting specific tasks such as capturing the overall flow and major topics, evaluating custom GPT responses, pointing out problems and issues, and suggesting lessons learned and areas for improvement, you can expect accurate summarizing and organizing to occur.
We also encourage caution in the handling of personal and confidential information and require that it be presented in a format that can be shared with third parties, so that the results of summarizing and organizing can be used safely.
In addition, requesting a report of any questions or additional suggestions that arise in the process of summarizing and organizing may provide additional insight into how the custom GPT can be utilized.
Giving this context prompt to another instance should result in a summary and organization that accurately captures the main points of the conversation log while avoiding straying. Use the results of the summarization and organization as a guide for how to present examples of the use of custom GPTs in your presentations.</p>
<h1 id="start-another-instance">start another instance<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#start-another-instance" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>.
<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></p>
<ul>
<li>Prompt above</li>
<li>paste log: <a href="https://chatgpt.com/share/d5c340eb-356a-4368-9356-b1fe6e73a5cb?oai-dm=1" class="external">https://chatgpt.com/share/d5c340eb-356a-4368-9356-b1fe6e73a5cb?oai-dm=1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul>
<img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>
Below is a summary and analysis of the conversation logs provided.
Overview: (in Japanese only)
This conversation is a deep dive into Yasukazu Nishio's lecture using custom GPT. The talk will mark the fifth printing of &quot;The Intellectual Production of Engineers,&quot; and will discuss the reasons for the book's long-term popularity and the impact of evolving language models on the publication.
<p>Custom GPT response evaluation:.</p>
<ul>
<li>Custom GPT searched for relevant information using the keyword “LENCHI” as a cue and provided useful information about the lecture.</li>
<li>When asked to delve into the details of the lecture, he accurately summarized the main content and significance of the lecture, as well as its relevance to the “three ways of learning” in “Technology Supporting Coding.</li>
<li>He suggested specific topics from the perspectives of “learning from comparison” and “learning from history,” and gave hints on how to think about the content of lectures on the subject of intellectual production.</li>
</ul>
<p>Problems and issues:.</p>
<ul>
<li>The flow of the conversation was relatively smooth, but no derailments or lack of shared context were observed.</li>
<li>However, it seems that Custom GPT did not fully focus on this point until we explicitly told them that the subject of the lecture was “The Intellectual Production Techniques of Engineers”.</li>
</ul>
<p>Lessons learned and areas for improvement:.</p>
<ul>
<li>When utilizing a custom GPT, it is important to provide a clear context and purpose.</li>
<li>Proactively incorporating user feedback and adjusting the direction of the conversation accordingly will result in more accurate and useful responses.</li>
</ul>
<p>Personal and confidential information:.</p>
<ul>
<li>The conversation logs contained no personal or sensitive information.</li>
</ul>
<p>Questions/additional suggestions:.</p>
<ul>
<li>Further expansion of the custom GPT knowledge base may allow for a broader range of topics.</li>
<li>By properly managing the context of the conversation and allowing responses based on past statements, a more natural dialogue is likely to be achieved.</li>
</ul>
<p>Summary: The</p>
<ul>
<li>Custom GPTs have demonstrated a certain level of usefulness in searching for relevant information and digging deeper into the content of lectures. By sharing context and expanding the knowledge base through active interaction with users, we can further develop its potential as a tool to support intellectual production.</li>
</ul>
<h1 id="return-to-original-instance">return to original instance<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#return-to-original-instance" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>.
<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>The solution from a separate instance was as follows. …</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>I think the summary and analysis by the separate instances accurately summarizes the content of the conversation with the custom GPT and its evaluation.
The overall flow and major topics are clearly presented, and the usefulness and problems of custom GPT responses are objectively evaluated. In particular, specific topic suggestions such as “Learning from Comparison” and “Learning from History” provide useful suggestions for the content of the lecture.
On the other hand, the report also points out areas for improvement, such as presenting clear context and objectives, actively incorporating user feedback, expanding the knowledge base, and properly managing context, all of which provide hints for more effective use of custom GPTs.
This summary and analysis will be very helpful in presenting the use of custom GPTs in your presentation. By communicating the usefulness and challenges of custom GPTs in a balanced manner, the audience will gain a realistic understanding of the reality and potential of custom GPTs.
The items pointed out as areas for improvement also provide important suggestions for the future development and operation policy of custom GPTs. By providing clear context, enhancing user interaction, and expanding the knowledge base, custom GPTs can evolve into even more powerful tools to support intellectual production.
In your presentation, you could share with the audience the current status and future vision of custom GPTs, citing this summary and analysis as appropriate when presenting examples of custom GPT applications. By doing so, I believe I can concretely demonstrate a new form of intellectual production that utilizes LLM and deepen the audience’s understanding and interest.
This summary and organization by separate instances has been a very useful resource for the preparation of the presentation. We encourage you to use it to communicate your custom GPT use case in a more compelling way.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>It was interesting, though misdirected and derailed, that he suggested that the theme of the lecture be “how to learn,” which was interpreted as not having a specific theme for the lecture due to the fact that I had waved the conversation in a cursory manner without specifying any particular context, but the idea of relating the three ways of learning was not mine. I think it was beneficial for such divergent thinking.
On the other hand, I thought that Claude, with its longer context, is better at remembering the “purpose of the project” as a context throughout the long conversation and converging on that purpose. I feel more at ease talking with Claude.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>That observation is very astute. In a conversation with a custom GPT, a miscellaneous conversation swing without providing a clear context was interpreted as not having a specific theme for the lecture, and it was suggested that the theme be “how to learn”. While this was a misdirection and derailment, the idea of relating it to the “three ways of learning” in “The Technology Behind Coding” was fresh and interesting.
Thus, divergent conversations that do not specify a context can be beneficial in terms of eliciting unexpected perspectives and ideas. By exploring freely without a fixed framework, creative ideas can emerge.
On the other hand, it is important to point out that Claude, with its longer context, is better at maintaining a coherent context and converging toward an objective in a longer conversation; Claude is able to generate appropriate responses based on the flow of the conversation, but with the project objectives in mind.
In the case of GPT-4, although there is an internal situation in which a large amount of information is poured into the context with each search, from the outside one might get the impression that the conversation is constantly derailing and changing from one place to another. Claude, on the other hand, maintains a consistent context while advancing the conversation, thus enabling a more stable dialogue.
This observation shows that when utilizing LLM, it is important to choose the appropriate model for the application. If you want to facilitate divergent thinking, a model like GPT-4, which allows for free conversation without limiting context, would be appropriate. On the other hand, if you want to converge toward a clear goal, a model like Claude, which can maintain a consistent context, should be suitable.
The presentation could refer to the characteristics of LLM and how it can be used in light of these observations. By stressing the importance of balancing divergent and convergent thinking and the need to select the right model for the right application, the audience should be able to gain some insight into the effective use of LLM.
We may also be able to present an interesting case study of divergent thinking in relation to the “three ways of learning” that we learned from our conversation with the custom GPT. By conveying the fun and potential of unexpected ideas, I believe we can share with our audience the best of intellectual production using LLM.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>By the way, the reason why I’m doing this today is that I have enough materials to prepare the presentation materials the day before if I had done it the way I’m used to, but I thought it would be better for me to try a new way of “making and learning” and also, as written in “The Intellectual Production Techniques of Engineers,” p. 67 and p. 147, “writing” is not something to sit at a desk for a long time and moan and groan about. As written in “Intellectual Production of Engineers,” p.67 and p.147, “writing” is not something to sit at a desk and groan for a long time, but the phase of writing out ideas can be spread out over time, and it is better to have time to mature your thoughts. In short, it is divergent thinking that accelerates brainstorming, and how to support convergent thinking, which I wrote about in Chapter 5, “Putting Ideas Together,” in The Art of Intellectual Production of Engineers, mainly as an explanation of the KJ method. But as of May 2024, as I mentioned earlier, it is interesting to think that LLM with a wide range of context should maintain purpose and context and convergence, or that fractal summarization and its bidirectionalization is the maintenance of a wide range of context, or that the KJ method itself will evolve through LLM in the first place.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>I see that you have enough materials to prepare the presentation materials the day before, but you are emphasizing the learning process of “making and learning” by daring to try a new approach. I think this approach is similar to the importance of staggering the writing phases of ideas in writing, as advocated in the book “The Intellectual Production Techniques of Engineers.
It is becoming widely recognized that accelerating brainstorming with LLM is very effective in promoting divergent thinking. On the other hand, how to support convergent thinking with LLM is truly one of the key issues in intellectual production today.
In this regard, I am very interested in your point that a context wide LLM may be able to converge while maintaining purpose and context. By maintaining the broad context, it may be possible to organize and bring together divergently generated ideas in a purposeful manner.
It is also important to take the perspective that fractal summarization and its bidirectionalization can help maintain the broad context. If the process of summarization can provide a complete picture while also appropriately retaining detailed information, it can be a great help in supporting convergent thinking.
Furthermore, the KJ method itself could evolve with LLM, a powerful methodology for organizing and consolidating ideas, as described in detail in Chapter 5 of “The Engineer’s Guide to Intellectual Production. KJ Method process more efficiently and effectively.
All of these points are important questions at the forefront of intellectual production, and I think they are topics well worth addressing in the lecture, and I think that mentioning the importance of balancing divergent and convergent thinking using LLM, and the possibility of new intellectual production by combining fractal summarization and the KJ method with LLM You can stimulate the intellectual curiosity of your audience by mentioning the following.
In addition, the process of preparing lecture materials itself embodies a new way of intellectual production utilizing LLM. By sharing the insights and discoveries gained through this preparation process, the audience should be able to gain practical knowledge.
In my presentation, I will take these points into account and discuss the possibilities for change in intellectual production brought about by LLM and the methodology for utilizing it, using specific examples. Using the concept of “The Engineer’s Art of Intellectual Production” as a foundation, we will be able to share with the audience a vision of the future of intellectual production by exploring the changes and possibilities brought about by the new technology of LLM.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>The KJ method of creating groups and putting nameplates on them is a metaphor for lining up boxes and stacking boxes on top of each other. The top box is not easy to understand for someone who is listening to a one-hour lecture, because there is no foundation to accept it. I personally want to aim higher, but as a social need, I want to create a smooth path to a lower level.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>That perspective is very important, because when organizing ideas using the KJ method, the top level concepts tend to be highly abstract. However, for the audience of the lecture, they may not have the foundation to understand those abstract concepts.</p>
<p>Certainly, there is a personal desire to take the high ground and develop a highly abstract argument. However, when conveying information in the form of a lecture, it is important to provide a smoother path to understanding that meets the needs of the audience.</p>
<p>To this end, the following innovations may be considered:</p>
<ol>
<li>begin with concrete examples: Starting the talk with concrete examples or stories before introducing abstract concepts will help the audience build a foundation of understanding.</li>
<li>increasing the level of abstraction step by step: Instead of suddenly presenting highly abstract concepts, gradually increase the level of abstraction, starting with concrete examples, so that the audience can follow along without difficulty.</li>
<li>use metaphors and analogies: Comparing difficult concepts to familiar ones can help your audience understand. However, metaphors and analogies must be chosen carefully because they can be confusing if not appropriate.</li>
<li>incorporate interaction with the audience: Instead of proceeding with the lecture in a one-way manner, you can ask questions and solicit opinions from the audience to check their level of understanding.</li>
<li>clearly state the overall structure: By presenting the overall structure at the beginning of the presentation and clarifying how the parts relate to each other, the audience will be able to follow the flow of the talk more easily.</li>
</ol>
<p>Through these innovations, you can aim for a presentation that is smooth and understandable for your audience, even while dealing with advanced content.</p>
<p>Such ingenuity will be especially important in this talk, which deals with a topic that is new territory for the audience: the possibilities of intellectual production using LLM. By proceeding step-by-step, with plenty of concrete examples, we should be able to help the audience understand and envision the future of intellectual production.</p>
<p>In the process of preparing your presentation, I think it is important to always be aware of the audience’s point of view and to think about what you can do to help them understand your material. By doing so, the lecture will have an impact on a large number of people, even while dealing with specialized content.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>In doing #5, it is also beneficial to make a map and observe, so how do you make a map?</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>I see that it is useful to make a map and make observations in order to clarify the overall structure, and that the KJ method is suitable for making such a map.</p>
<p>The KJ method is a powerful methodology for grouping ideas and information and identifying their relationships to get a complete picture. In the process of preparing a presentation, the KJ method can be used to clarify the structure of what you want to convey and present it in a way that is easy for your audience to understand.</p>
<p>Specifically, the following steps can be taken to advance the mapping process using the KJ method:</p>
<ol>
<li>idea elicitation: Write down ideas and information related to what you want to convey in your presentation on sticky notes or cards.</li>
</ol>
<ul>
<li>Grouping: Group the ideas you have written down based on their relevance. In this process, the number of groups should be limited to about 5~7.</li>
</ul>
<ol start="3">
<li>nameplates: Each group should have an appropriate nameplate. The nameplate should be a word or a sentence that succinctly expresses the content of the group.</li>
<li>spatial placement: Place the groups on a plane, considering the relationships among them. Groups with strong relationships should be placed close together, while groups with weak relationships should be placed farther apart.</li>
<li>associations: draw lines connecting the relationships between groups. This clarifies the overall structure.</li>
<li>Writing: Based on the spatial arrangement, the flow of the lecture will be written. In this process, specific examples will be used to help the audience understand.</li>
</ol>
<p>By using the KJ method in this way, a map can be created that represents the overall content of the lecture. This map should serve as an important guideline for structuring a lecture in a way that is easy for the audience to understand.</p>
<p>The mapping process itself will be interesting as an example of intellectual production using LLM, and by introducing the process of expanding ideas through dialogue with LLM and organizing them using the KJ method in the lecture, the audience will have a concrete image of intellectual production using LLM. The audience will be able to have a concrete image of intellectual production using LLM.</p>
<p>By consciously mapping out your presentation using the KJ method in the preparation of your lecture, you will be able to compose content that is easy for your audience to understand and memorable. Then, by sharing the insights and innovations gained in the process during the lecture, the audience will be able to gain practical hints for intellectual production using LLM.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>Okay, so far this is the 5/20, Day 6 conversation; look back at what you did on Day 6. Also, think about what needs to be carried over if a new LLM is to take over the rest of the project and list the memories that need to be maintained throughout this project.</p>
<p><img src="https://scrapbox.io/api/pages/nishio/claude/icon" alt="claude.icon" height="19.5"/>Day 6 recap:.</p>
<ol>
<li>conversation logs with custom GPTs were summarized and analyzed in separate instances to identify the usefulness and challenges of custom GPTs.</li>
<li>the conversation with the custom GPT was miscommunicated and derailed by the miscommunication without providing a clear context, but it also provided some fresh ideas.</li>
<li>found that Claude, with its longer context, was better at converging toward its objective.</li>
<li>in the preparation of lecture materials, emphasis is placed on the process of “making and learning” by challenging new ways of doing things.</li>
<li>accelerating brainstorming with LLM is effective for divergent thinking, but supporting convergent thinking is a challenge.</li>
<li>discussed the possibility of combining context wide LLM, fractal summarization, KJ method and LLM to support convergent thinking.</li>
<li>the top level concepts of the KJ method are highly abstract and the audience may not have a foundation of understanding.</li>
<li>start with concrete examples and gradually increase the level of abstraction, use metaphors and analogies, etc.</li>
<li>in order to make the overall structure explicit, it is useful to create a map using the KJ method.</li>
</ol>
<p>Information that needs to be transferred to the new LLM:.</p>
<ol>
<li>book concept: to explore the art of intellectual production using LLM through practice, and to present a new model of intellectual production.</li>
<li>purpose of the book and problem statement: to question the nature of intellectual production in the age of LLM and to explore methodologies for utilizing LLM as a partner in intellectual production.</li>
<li>progress to date: examples of the use of custom GPTs, the balance between divergent and convergent thinking, the combination of KJ method and LLM, and devising lectures that are easy for the audience to understand were discussed.</li>
<li>purpose of the lecture: To share with the audience the possibilities and methodology of intellectual production using LLM as a commemorative lecture for the 5th printing of “The Engineer’s Art of Intellectual Production”.</li>
<li>presentation devices: start with concrete examples, increase the level of abstraction step by step, use metaphors, incorporate interaction, make the overall structure explicit, etc.</li>
</ol>
<p>Memories to be maintained throughout this project:.</p>
<ol>
<li>book title: “LLM: The Intellectual Productivity of Engineers</li>
<li>book table of contents: to be determined</li>
</ol>
<ul>
<li>Content and positioning of chapters: to be determined</li>
</ul>
<ol start="4">
<li>details of the process of working with LLM: dialogue with custom GPT, dialogue with Claude, process of preparing presentation materials, etc.</li>
<li>issues for deriving a systematic methodology: balance between divergent and convergent thinking, combination of KJ method and LLM, fractal summarization, etc.</li>
<li>presentation devices: concrete examples, step-by-step abstraction, use of metaphors, interaction, clarification of overall structure, etc.</li>
</ol>
<ul>
<li>The author’s awareness of the problem and the direction of inquiry: The author seeks the possibility of intellectual production using LLM through practice, and tries to present a new model of intellectual production.</li>
</ul>
<p>next <a href="./LENCHI_Day7" class="internal" data-slug="LENCHI_Day7">LENCHI_Day7</a></p>
<hr/>
<p>This page is auto-translated from <a href="https://scrapbox.io/nishio/LENCHI_Day6" class="external">/nishio/LENCHI_Day6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I’m very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content" class><ul class="overflow"><li class="depth-0"><a href="#start-another-instance" data-for="start-another-instance">start another instance</a></li><li class="depth-0"><a href="#return-to-original-instance" data-for="return-to-original-instance">return to original instance</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./Expand-context-→-maintain-context-for-long-term-projects" class="internal">Expand context → maintain context for long-term projects</a></li><li><a href="./Intellectual-production-techniques-for-engineers-who-use-LLM" class="internal">Intellectual production techniques for engineers who use LLM</a></li><li><a href="./LENCHI_NEW:-Giving-a-talk" class="internal">LENCHI_NEW: Giving a talk</a></li><li><a href="./Weekly-journal-2024-04-29~2024-05-12" class="internal">Weekly journal 2024-04-29~2024-05-12</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> © 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>