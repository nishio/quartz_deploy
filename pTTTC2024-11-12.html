<!DOCTYPE html>
<html lang="en"><head><title>pTTTC2024-11-12</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ü™¥ Quartz 4.0"/><meta property="og:title" content="pTTTC2024-11-12"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="pTTTC2024-11-12"/><meta name="twitter:description" content="Nittele NEWS x 2024 House of Representatives Election x Broad Listening I forked it anyway. github.com/nishio/shugiinsenyo2024-tttc % pip install langchain_openai % pip install python-dotenv Error after getting to embedding % pip install --upgrade langchain % pip install -U langchain-community This fixed it."/><meta property="og:description" content="Nittele NEWS x 2024 House of Representatives Election x Broad Listening I forked it anyway. github.com/nishio/shugiinsenyo2024-tttc % pip install langchain_openai % pip install python-dotenv Error after getting to embedding % pip install --upgrade langchain % pip install -U langchain-community This fixed it."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="Nittele NEWS x 2024 House of Representatives Election x Broad Listening I forked it anyway. github.com/nishio/shugiinsenyo2024-tttc % pip install langchain_openai % pip install python-dotenv Error after getting to embedding % pip install --upgrade langchain % pip install -U langchain-community This fixed it."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/pTTTC2024-11-12"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/pTTTC2024-11-12"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="Nittele NEWS x 2024 House of Representatives Election x Broad Listening I forked it anyway. github.com/nishio/shugiinsenyo2024-tttc % pip install langchain_openai % pip install python-dotenv Error after getting to embedding % pip install --upgrade langchain % pip install -U langchain-community This fixed it."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="pTTTC2024-11-12"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">ü™¥ Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href>pTTTC2024-11-12</a></div></nav><h1 class="article-title">pTTTC2024-11-12</h1><p show-comma="true" class="content-meta"><span>Nov 20, 2024</span><span>8 min read</span></p></div></div><article class="popover-hint"><ul>
<li><a href="./Nittele-NEWS-x-2024-House-of-Representatives-Election-x-Broad-Listening" class="internal alias" data-slug="Nittele-NEWS-x-2024-House-of-Representatives-Election-x-Broad-Listening">Nittele NEWS x 2024 House of Representatives Election x Broad Listening</a>
I forked it anyway.
<a href="https://github.com/nishio/shugiinsenyo2024-tttc" class="external">https://github.com/nishio/shugiinsenyo2024-tttc<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul>
<p><code>% pip install langchain_openai</code>
<code>% pip install python-dotenv</code></p>
<p>Error after getting to embedding
<code>% pip install --upgrade langchain</code>
<code>% pip install -U langchain-community</code>
This fixed it.</p>
<p>HDBSCAN in (7574, 3072) dimensions takes 5 minutes</p>
<ul>
<li>(1000, ‚Ä¶) would be 5 seconds after random sampling to</li>
<li>The dimension of the embedding vector probably only comes into play on a linear order, so I don‚Äôt think it needs to be shortened.</li>
</ul>
<p>I was going to extract about 30-100 clusters.
Unlike k-means, the number of clusters cannot be specified in the first place.</p>
<ul>
<li>If min_cluster_size=5 is smaller, it will increase.
<ul>
<li>However, ‚ÄúTwo data clusters!‚Äù is subtle</li>
</ul>
</li>
<li>min_samples=2 can be increased by decreasing
<ul>
<li>whatever the principle is</li>
<li>Seems to be about density calculations.</li>
</ul>
</li>
<li>max_cluster_size=30
<ul>
<li>This will prevent huge clusters from appearing.</li>
<li>It doesn‚Äôt break up huge clusters, and it takes a little more experimentation to understand the behavior in this area.</li>
</ul>
</li>
</ul>
<p>With 1000 cases, (min_cluster_size, min_samples) = (5, 2), I got 10 clusters.</p>
<ul>
<li>(2, 2) would increase to 38 clusters, but ‚Äútwo would mean a cluster‚Äù.
<ul>
<li>Isn‚Äôt that a bit much?</li>
<li>But conversely, everything else is considered sparse area data.</li>
<li>When there is very little data, ‚ÄúI have no choice but to try (2, 2)‚Äú.
<ul>
<li>Nuance like, ‚ÄúIt could be a fluke, it could be dismissed when more data is gathered, but at this stage, it‚Äôs a likely candidate.‚Äù</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The more data there is, the higher the probability that the density of data exceeds a fixed threshold.</p>
<ul>
<li>7,000 cases, (5, 2) made 79 clusters.</li>
<li>But well, the problem is that HDBSCAN is nonlinearly heavy.
<ul>
<li>Running a parameter search on a large amount of data is expensive, but sampling changes the behavior.</li>
<li>If it is a random sampling, the inference that ‚Äúif it is like this when there are 1000 cases, it will be like this when there are 7000 cases‚Äù is likely to be valid.
<ul>
<li>Well, doing normal math, 1000 (2, 2) is equivalent to 7000 (14, 14).</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Extract ‚Äúwhy are these lumped together‚Äù for these data</p>
<p>:</p>
<pre><code>```json
[
    {
        &quot;explanation&quot;: &quot;...&quot;,
        &quot;label&quot;: &quot;...&quot;
    }
]
</code></pre>
<pre><code>
It's annoying that sometimes it comes back in a different way than planned.

It should now be possible to make a call to clarify the JSON schema, so we'll look into it.

2024-11-13
TTTC for Nittele, Azure support and JSON enforcement for output are all included, too kind and impressive!

79 clusters were created from 7574 data
- 739 data used, coverage of 9.8%.

I got good experimental results as I thought, so I want to do the same thing with the data I can publish and write an article about it.
- I'd also like to do a story on the Yasuno team's case with Nittele.
- I'd like to write an article about the public opinion map.
    - You have three!

![image](https://gyazo.com/aa54ff46f8ab889e5458cac0172fc9a4/thumb/1000)
- Conventional TTTC tries to classify all data into clusters
    - So I hope it is a cluster of clearly separated islets like (1).
    - In (2) and (3), multiple topics got mixed up, and there were things like &quot;AI's explanation and a very different story are mixed up.
- The experiment we did this time was to stop &quot;categorizing all the data&quot; and cut out only the densely concentrated areas.
    - 79 clusters were created. This one only took out the dense parts, so the clusters that were created are dense.
    - but there are many opinions that have not been selected for the cluster. Maybe more than you imagine, about 90% of them have been discarded.
- Neither of these two is better than the other, but both have advantages and disadvantages and should be used well.

The current TTTC, which shows the whole picture with scatter plots and forced clustering, is well suited to satisfy the desire [[Let's start with the broad strokes...]] [[I want to get the whole picture...]].
- During the gubernatorial campaign, it was like they'd shut up and show it to the people across the net OR the policy team would read it and refer to it.
    - [[Nittele NEWS x 2024 House of Representatives Election x Broad Listening]] needed to provide &quot;commentary&quot; for viewers
    - The process clarified the need to not only present the big picture, but also to &quot;dig deeper into deep opinions.
        - In the process of doing this, the current TTTC only allows you to &quot;mouse hover over a point to show it&quot; and show N=1.
        - Support is scarce in that &quot;finding an opinion to focus on&quot; area.
            - You just look at a few at random and leave it up to luck.
            - You end up looking at all 7,000 cases.
    - This new experiment will improve this area.
        - Reduce the burden of &quot;looking at 79 clusters with high concentration instead of looking at all 7,000 cases.&quot;
        - Increased persuasiveness by being able to present as &quot;N=5~30 opinions instead of N=1&quot;.

2024-11-14
[[Difference between DBSCAN and HDBSCAN#67352797aff09e00003bcfa4|67352797aff09e00003bcfa4]]
If this is the case, my use case would be better to do a light DBSCAN with different parameters.
Let's extract 100 clusters and do KJ method for them.

- [[distribution of text-embedded vectors]]

Even if I were to use HDBSCAN, Leaf Clustering seems better suited for my purposes.
[Parameter Selection for HDBSCAN* ‚Äî hdbscan 0.8.1 documentation](https://hdbscan.readthedocs.io/en/latest/parameter_selection.html#leaf-clustering)

---
Special Feature Sort ‚úÖ

I tried re-running the system with another TTTC data (AI PubCom), a mechanism to extract dense clusters, and it worked easily.
- [https://github.com/nishio/ai_kj/blob/main/dense_cluster_extruction.ipynb](https://github.com/nishio/ai_kj/blob/main/dense_cluster_extruction.ipynb)
- [[Extraction of dense masses]]

AI's idea of &quot;interesting and dense clusters&quot;
- Personally, I find the lower scores more interesting and unfamiliar.
- Well, this may be partly because we haven't taught the AI what the purpose of research is and what kind of things are interesting.
Would it be better for the AI to read and critique the list after it is made, rather than individually give the degree of interest?
The prompt &quot;a perspective like no other&quot; sounds good, interesting.

&lt;img src='https://scrapbox.io/api/pages/nishio/gpt/icon' alt='gpt.icon' height=&quot;19.5&quot;/>Clusters that introduce a unique perspective and their originality
- C16: Illegal Content Risk of AI Training Data
    - It is unique in its perspective on ethical concerns in AI learning, with a special focus on the presence of illegal content, particularly the possible inclusion of child pornography. While other clusters focus on copyright and unauthorized use, this one takes a step further into the ethical boundaries of AI technology and expands its perspective to legal risks.
- C12: Concerns about misuse of AI technology
    - It is unique in that it refers to risks such as misuse for commercial purposes or fraudulent activities, as well as economic impact that threatens the lives of others, and introduces the perspective that the use of AI goes beyond infringement of creators' rights and relates to the safety of society as a whole.
- C4: Importance of Transparency and Accountability
    - It differs from the other clusters in its emphasis on transparency regarding the development and training process of AI systems and its call for specific measures at the intersection of technology and ethics.

These clusters offer creative perspectives on the application of AI technology in ethics, legal risks, and transparency.

[https://chatgpt.com/share/6735c2e5-5bac-8011-bccc-d8ffd64fd1d9](https://chatgpt.com/share/6735c2e5-5bac-8011-bccc-d8ffd64fd1d9)

---
requirements.txt
- [https://gist.github.com/nishio/756cd4c6dee7203cc6a32172ce1e2f78](https://gist.github.com/nishio/756cd4c6dee7203cc6a32172ce1e2f78)

:

</code></pre>
<p>scatter/pipeline/steps/embedding.py:3: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:</p>
<blockquote>
<blockquote>
<p>from langchain.embeddings import OpenAIEmbeddings</p>
</blockquote>
</blockquote>
<p>with new imports of:</p>
<blockquote>
<blockquote>
<p>from langchain_community.embeddings import OpenAIEmbeddings
You can use the langchain cli to <strong>automatically</strong> upgrade many imports. Please see documentation here <a href="https://python.langchain.com/docs/versions/v0_2/" class="external">https://python.langchain.com/docs/versions/v0_2/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
from langchain.embeddings import OpenAIEmbeddings
/Users/nishio/shugiinsenyo2024-tttc/venv/lib/python3.10/site-packages/langchain/chat_models/<strong>init</strong>.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:</p>
</blockquote>
</blockquote>
<p><code>from langchain_community.chat_models import ChatOpenAI</code>.</p>
<p>To install langchain-community run <code>pip install -U langchain-community</code>.
warnings.warn(
venv/lib/python3.10/site-packages/langchain/chat_models/<strong>init</strong>.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:</p>
<p><code>from langchain_community.chat_models import ChatOpenAI</code>.</p>
<p>To install langchain-community run <code>pip install -U langchain-community</code>.
warnings.warn(</p>
<pre><code>

I'm not going to worry about it once.
- I was just messing around with it and it got complicated.

Just a note on the &quot;complications.&quot;
:

</code></pre>
<p>from huggingface_hub import HfApi, HfFolder, Repository, hf_hub_url, cached_download
ImportError: cannot import name ‚Äòcached_download‚Äô from ‚Äòhuggingface_hub‚Äô (/Users/nishio/shugiinsenyo2024-tttc/venv/lib/python3.10/site-packages/huggingface_hub/<strong>init</strong>.py)</p>
<pre><code>
&lt;img src='https://scrapbox.io/api/pages/nishio/gpt/icon' alt='gpt.icon' height=&quot;19.5&quot;/>This error may be caused by a newer version of the Hugging Face Hub library. cached_download function has been removed or deprecated in recent versions and an alternative method is recommended.
- After this, AI recommends `pip install huggingface_hub==0.12.0`, but the last one that worked properly was `huggingface-hub==0.25.1`, so you're backtracking too many versions.
- Well, it's a place where information may not be up-to-date or halcyonized.

:

</code></pre>
<p>ImportError: cannot import name ‚ÄòHF_HUB_DISABLE_TELEMETRY‚Äô from ‚Äòhuggingface_hub.constants‚Äô (/Users/nishio/shugiinsenyo2024-tttc/venv/lib/python3.10/site-packages/huggingface_hub/constants.py)</p>
<pre><code>

---
This page is auto-translated from [/nishio/pTTTC2024-11-12](https://scrapbox.io/nishio/pTTTC2024-11-12) using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at [@nishio_en](https://twitter.com/nishio_en). I'm very happy to spread my thought to non-Japanese readers.
</code></pre></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./AI-Hammer-Pattern" class="internal">AI Hammer Pattern</a></li><li><a href="./Diary-2024-11-14" class="internal">Diary 2024-11-14</a></li><li><a href="./High-dimensional-data-analysis-study-group" class="internal">High-dimensional data analysis study group</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> ¬© 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>