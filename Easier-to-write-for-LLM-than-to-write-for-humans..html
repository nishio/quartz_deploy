<!DOCTYPE html>
<html lang="en"><head><title>Easier to write for LLM than to write for humans.</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ğŸª´ Quartz 4.0"/><meta property="og:title" content="Easier to write for LLM than to write for humans."/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Easier to write for LLM than to write for humans."/><meta name="twitter:description" content="2023-04-06 gfx Youâ€™d be surprised how often we get extremely accurate answers when we ask GPT-4 about TypeScript. I think this is probably because there are so many good TypeScript texts in the world."/><meta property="og:description" content="2023-04-06 gfx Youâ€™d be surprised how often we get extremely accurate answers when we ask GPT-4 about TypeScript. I think this is probably because there are so many good TypeScript texts in the world."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="2023-04-06 gfx Youâ€™d be surprised how often we get extremely accurate answers when we ask GPT-4 about TypeScript. I think this is probably because there are so many good TypeScript texts in the world."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/Easier-to-write-for-LLM-than-to-write-for-humans."/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/Easier-to-write-for-LLM-than-to-write-for-humans."/><link rel="icon" href="./static/icon.png"/><meta name="description" content="2023-04-06 gfx Youâ€™d be surprised how often we get extremely accurate answers when we ask GPT-4 about TypeScript. I think this is probably because there are so many good TypeScript texts in the world."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Easier-to-write-for-LLM-than-to-write-for-humans."><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">ğŸª´ Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> â¯ </p></div><div class="breadcrumb-element"><a href>Easier to write for LLM than to write for humans.</a></div></nav><h1 class="article-title">Easier to write for LLM than to write for humans.</h1><p show-comma="true" class="content-meta"><span>Nov 18, 2023</span><span>5 min read</span></p></div></div><article class="popover-hint"><p>2023-04-06</p>
<blockquote>
<p><a href="https://twitter.com/__gfx__/status/1643561940848091136" class="external"><strong>gfx</strong><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Youâ€™d be surprised how often we get extremely accurate answers when we ask GPT-4 about TypeScript. I think this is probably because there are so many good TypeScript texts in the world.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/__gfx__/status/1643565160328736768" class="external"><strong>gfx</strong><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> However, I have no idea about the new features recently and canâ€™t get attached to them. So no satisfies will be used in the code that GPT-4 will write.
This gap is not so easyâ€¦ for those who know what theyâ€™re doing, but it might be hard to be practical.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/omochimetaru/status/1643572683320459267" class="external">omochimetaru<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> than creating a new, highly functional language,
It is more efficient to use old languages with AI support for development,
I donâ€™t like the idea that this would put a brake on the evolution of the languageâ€¦</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/__gfx__/status/1643575579508355077" class="external"><strong>gfx</strong><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> That said, I think that concern is unfounded, as we have already achieved engines like bing that learn in real time.
Rather, I am more concerned that even if a new language is created, the sample size will be too small for AI to write well and it will not spreadâ€¦</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/omochimetaru/status/1643576125011165185" class="external">omochimetaru<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> I see.
I wonder if the AI is smart enough, even if the text is only about the official specs, if it can help us understand and use new concepts from it.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1643812867773452290" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> The technology is already in place and will soon come down to the average consumer â€œ<a href="./Ability-to-give-LLMs-a-knowledge-package-of-your-area-of-interest" class="internal alias" data-slug="Ability-to-give-LLMs-a-knowledge-package-of-your-area-of-interest">Ability to give LLMs a knowledge package of your area of interest</a>â€ will come down to the general public soon. When that happens, authors of new languages will create knowledge packages for LLMs, and people who want to use the language will be able to load them into LLMs and use them.</p>
</blockquote>
<ul>
<li>I wrote this and implemented it in <a href="./ChatGPT-Plugins" class="internal alias" data-slug="ChatGPT-Plugins">ChatGPT Plugins</a> on 4/7, and it was provided under the name <a href="./Assistants-API" class="internal alias" data-slug="Assistants-API">Assistants API</a> at <a href="./OpenAI-DevDay" class="internal alias" data-slug="OpenAI-DevDay">OpenAI DevDay</a> on 11/7 (related: <a href="./Retrieval-augmented-Language-Model" class="internal alias" data-slug="Retrieval-augmented-Language-Model">Retrieval-augmented Language Model</a>).</li>
</ul>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1643813597792071680" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Creating knowledge packages is actually easier than creating documents for human readers. Because humans have limited short-term memory, it is necessary to provide knowledge in a â€œgood orderâ€, and this is very hard for the author.
- <a href="./Writing-is-one-dimensional" class="internal alias" data-slug="Writing-is-one-dimensional">Writing is one-dimensional</a></p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1643813862008033283" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Rather, it is better to identify â€œwhat information is missingâ€ based on usersâ€™ questions and add it, and it is important to create a system to do so. It is important to build a system to do that.</p>
</blockquote>
<p>2023-11-10</p>
<blockquote>
<p><a href="https://twitter.com/tokoroten/status/1722613867459870989" class="external">tokoroten<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Iâ€™ve been able to make a custom model by feeding PDF into ChatGPT,
â€œA book is an additional data set to the LLMâ€ feels like a definite future.</p>
<p>E-book services that can work with LLMs are going to be the next dominant e-book service.
The age when a stack of books will be eaten up by LLMs, which will then be useful.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/unnonouno/status/1722628474937172341" class="external">unnonouno<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Conversely, the writing process is going to be data creation that feeds the LLM (it no longer even needs to be in Japanese). Itâ€™s going to be a custom LLM creation service, not publishing.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722638049883082908" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Books are inefficiently efficient input to AI because information is forced to be one-dimensional for human readability.
I have a feeling that the next generation will be strong in those who can create information in a data structure that is convenient for AI.</p>
<p>(From Nishioâ€™s conversation log from April or so) <a href="./Easier-to-write-for-LLM-than-to-write-for-humans." class="internal alias" data-slug="Easier-to-write-for-LLM-than-to-write-for-humans.">Easier to write for LLM than to write for humans.</a></p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722775665345523735" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Iâ€™ll write the date and related links later w</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722778725996175712" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Just yesterday we were talking about connecting FAQs to LLMs, and these FAQs are not books, â€œ<a href="./a" class="internal" data-slug="a">a</a> format for transferring knowledgeâ€ and will be used more widely as the search gets better. Iâ€™m sure they will be used more widely as search becomes better and more precise in answering questions.</p>
</blockquote>
<ul>
<li><a href="./Cybozu-Days-2023-11-09" class="internal alias" data-slug="Cybozu-Days-2023-11-09">Cybozu Days 2023-11-09</a></li>
</ul>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722779478685110539" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> When it comes to moving from books to FAQs, â€œWhat should I know first?â€ What will I get from reading this book? etc., and for those who want to read the book in a one-dimensional way, you can give them one â€œnext question candidateâ€ for each answer.</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/tokoroten/status/1722783854761771161" class="external">tokoroten<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> There are cases where what we call FAQs are really FAQs and cases where the line is drawn by FAQs, so the former will be LLM It will be absorbed, but I donâ€™t think all of it will be incorporated because of the latter feature.
<a href="https://tokoroten.medium.com/%E6%83%85%E5%A0%B1%E2%85%B0Books-Uncollected" class="external">https://tokoroten.medium.com/æƒ…å ±â…°Books-Uncollected<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Manuscript Offerings-The%EF%BC%92-c5c48fd04a69
<img src="https://pbs.twimg.com/media/F-iOovuaEAAyiqR?format=png&amp;name=small#.png" alt="image"/> <img src="https://pbs.twimg.com/media/F-iOs6SbMAAdGZ9?format=png&amp;name=900x900#.png" alt="image"/></p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722785628868530357" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Maybe the latter will display a source label such as â€œofficial informationâ€ or â€œcommunityâ€ and the recipient will be able to make a decision based on that?</p>
</blockquote>
<blockquote>
<p><a href="https://twitter.com/nishio/status/1722788318386204728" class="external">nishio<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Also, there was a discussion about what to generate in the â€œGâ€ part of RAG, and many people try to create â€œanswersâ€ that propagate â€œtruthâ€ but I think that is a plot evil!  I prefer to generate â€œopinionsâ€ like â€œI thought this article might be useful in resolving your questions in terms of </p><summary based on user interest>â€¦â€<p></p>
</summary></blockquote>
<hr/>
<p>This page is auto-translated from <a href="https://scrapbox.io/nishio/%E4%BA%BA%E9%96%93%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AB%E6%9B%B8%E3%81%8F%E3%82%88%E3%82%8ALLM%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AB%E6%9B%B8%E3%81%8F%E6%96%B9%E3%81%8C%E6%A5%BD" class="external">/nishio/äººé–“ã®ãŸã‚ã«æ›¸ãã‚ˆã‚ŠLLMã®ãŸã‚ã«æ›¸ãæ–¹ãŒæ¥½<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. Iâ€™m very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./AI's-vague-sense-of-insecurity-study-group" class="internal">AI's vague sense of insecurity study group</a></li><li><a href="./Easier-to-write-for-LLM-than-to-write-for-humans." class="internal">Easier to write for LLM than to write for humans.</a></li><li><a href="./question-and-answer-network" class="internal">question and answer network</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> Â© 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>