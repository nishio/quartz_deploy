<!DOCTYPE html>
<html lang="en"><head><title>Observations on the Publishing Industry</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="🪴 Quartz 4.0"/><meta property="og:title" content="Observations on the Publishing Industry"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Observations on the Publishing Industry"/><meta name="twitter:description" content="The participants tweeted their thoughts on an appropriate topic, and then asked GPT4 to read and comment on the tweets. Then, the GPT4 is asked to respond to the tweet, and a human being responds to the GPT4’s response."/><meta property="og:description" content="The participants tweeted their thoughts on an appropriate topic, and then asked GPT4 to read and comment on the tweets. Then, the GPT4 is asked to respond to the tweet, and a human being responds to the GPT4’s response."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="The participants tweeted their thoughts on an appropriate topic, and then asked GPT4 to read and comment on the tweets. Then, the GPT4 is asked to respond to the tweet, and a human being responds to the GPT4’s response."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/Observations-on-the-Publishing-Industry"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/Observations-on-the-Publishing-Industry"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="The participants tweeted their thoughts on an appropriate topic, and then asked GPT4 to read and comment on the tweets. Then, the GPT4 is asked to respond to the tweet, and a human being responds to the GPT4’s response."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Observations-on-the-Publishing-Industry"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">🪴 Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Observations on the Publishing Industry</a></div></nav><h1 class="article-title">Observations on the Publishing Industry</h1><p show-comma="true" class="content-meta"><span>Apr 04, 2023</span><span>9 min read</span></p><ul class="tags"><li><a href="./tags/Future" class="internal tag-link">Future</a></li><li><a href="./tags/Diversity" class="internal tag-link">Diversity</a></li><li><a href="./tags/TheFutureofPublishing" class="internal tag-link">TheFutureofPublishing</a></li><li><a href="./tags/AI" class="internal tag-link">AI</a></li><li><a href="./tags/future" class="internal tag-link">future</a></li><li><a href="./tags/paper" class="internal tag-link">paper</a></li><li><a href="./tags/emotional" class="internal tag-link">emotional</a></li><li><a href="./tags/A" class="internal tag-link">A</a></li><li><a href="./tags/book" class="internal tag-link">book</a></li><li><a href="./tags/LLLM" class="internal tag-link">LLLM</a></li><li><a href="./tags/author" class="internal tag-link">author</a></li><li><a href="./tags/contributing" class="internal tag-link">contributing</a></li><li><a href="./tags/LLMvsPublishers" class="internal tag-link">LLMvsPublishers</a></li></ul></div></div><article class="popover-hint"><p>The participants tweeted their thoughts on an appropriate topic, and then asked GPT4 to read and comment on the tweets. Then, the GPT4 is asked to respond to the tweet, and a human being responds to the GPT4’s response.</p>
<pre><code>- Considerations about [[publishing business]]. First of all, by lowering the hurdle of &quot;writing a book-length manuscript,&quot; a wide variety of projects will be launched, and people who have not written books in the past, saying &quot;I don't have time to write&quot; or &quot;I don't get much for my time,&quot; will start writing.
</code></pre>
<ul>
<li>
<p>Next, the supply will increase too much and the readers will become the bottleneck. Readers will start saying, “I want AI to read and summarize,” “I can’t have a paper book read,” “Give me Markdown of the manuscript directly rather than Kindle or PDF. Publishing in “<a href="./Easy-format-for-AI-to-read" class="internal alias" data-slug="Easy-format-for-AI-to-read">Easy format for AI to read</a>” will begin.</p>
</li>
<li>
<p>Just as handwritten letters remained for their emotional value despite the proliferation of e-mail, paper books will remain in this age, but they will no longer have as their primary purpose the transmission of information as books have in the past.</p>
</li>
<li>
<p>After emotional paper books are separated and “<a href="./Books-that-AI-reads" class="internal alias" data-slug="Books-that-AI-reads">Books that AI reads</a>” become the standard for information transmission purposes, those books will be freed from the “moderate volume” constraint that paper books carried. There will be no need to work hard to compress dense content and no need to water down thin content.</p>
</li>
<li>
<p>After this, the reader’s measurement of the “value of the book” will change. The amount of money will be the denominator and “the amount that the LLM at hand will be able to say what it cannot say” will be the numerator. What a surprise, this can be quantitatively evaluated by a third party.</p>
</li>
<li>
<p>Here, there is a split in whether the author is paid when the LLM studies the contents of the book.</p>
</li>
<li>
<p>If there is payment, the weight of the “payment received for the amount of contribution to LLM by becoming LLM’s study data” will be larger than the “profit from purchases by human readers” of the author’s income. Those who can create something new are safe.</p>
</li>
<li>
<p>If LLMs can learn without payment, there will be no incentive for publishers or authors to publish. If this happens, the publishers will be wiped out, so I think they will lobby before they get to this point. I am not sure if a good compromise can be found between the publishers and LLM or if it will be an all-out war between the two sides…I wonder if the LLM side will get into publishing and take market share.</p>
</li>
<li>
<blockquote>
<p>Considerations on the publishing business. First of all, the hurdle of “writing a book-length manuscript” has been lowered, which has led to the launch of a wide variety of projects, and people who would not have written books in the past because they said they could not find time to write or that the actual income was too small for the time required will start writing.</p>
</blockquote>
<ul>
<li>GPT4: 1/ I agree about the future of publishing. Technological advances will lower the hurdle of “writing a book-length manuscript” and will bring a variety of projects and new authors. This will give readers more choices and revitalize the industry as a whole.<a href="./tags/Future" class="tag-link internal alias" data-slug="tags/Future">Future</a> of Publishing<a href="./tags/Diversity" class="tag-link internal alias" data-slug="tags/Diversity">Diversity</a></li>
</ul>
</li>
<li>
<blockquote>
<p>Next, the supply will increase too much and the readers will become the bottleneck. Readers will start saying, “I want AI to read and summarize,” “I can’t let it read a paper book,” “Give me Markdown of the manuscript directly rather than Kindle or PDF. Publishing will begin in a “format that is easy for an AI to read.”</p>
</blockquote>
<ul>
<li>GPT4: 2/ Increased supply will create a bottleneck of reader choice; demand for AI summaries and e-books will increase, leading to a shift to “AI-readable formats”. Publishing industry needs to adapt to technological advancements and provide new value.<a href="./tags/TheFutureofPublishing" class="tag-link internal alias" data-slug="tags/TheFutureofPublishing">TheFutureofPublishing</a><a href="./tags/AI" class="tag-link internal alias" data-slug="tags/AI">AI</a> Summaries</li>
</ul>
</li>
<li>
<blockquote>
<p>Just as handwritten letters remained for their emotional value despite the proliferation of e-mail, paper books will remain in this age, but they will no longer have as their primary purpose the transmission of information as books have in the past.</p>
</blockquote>
<ul>
<li>GPT4: 3/ Paper books will remain as emotionally valuable as handwritten letters. While information transmission will no longer be the primary purpose, demand will continue for works that emphasize sensitivity and artistry.<a href="./tags/future" class="tag-link internal alias" data-slug="tags/future">future</a> of publishing<a href="./tags/paper" class="tag-link internal alias" data-slug="tags/paper">paper</a> books<a href="./tags/emotional" class="tag-link internal alias" data-slug="tags/emotional">emotional</a> value</li>
</ul>
</li>
<li>
<blockquote>
<p>After emotional paper books are separated and “AI-read books” become the standard for information transfer purposes, those books will be freed from the “reasonable volume” constraint that paper books carried. There will be no need to work hard to compress dense content and no need to water down thin content.</p>
</blockquote>
<ul>
<li>GPT4: 4/ As “AI-read books” become mainstream for information transfer purposes, the “moderate volume” constraints of paper books will disappear. There will be no need to compress dense content or water down thin content. This will allow authors to convey information in a freer form and produce higher quality content.<a href="./tags/Future" class="tag-link internal alias" data-slug="tags/Future">Future</a> of Publishing<a href="./tags/A" class="tag-link internal alias" data-slug="tags/A">A</a> Books to be Read by AI</li>
</ul>
</li>
<li>
<blockquote>
<p>After this, the reader’s measurement of the “value of the book” will change. The amount of money will be the denominator and “the amount that the LLM at hand will be able to say what it cannot say” will be the numerator. What a surprise, this can be quantitatively evaluated by a third party.</p>
</blockquote>
</li>
<li>
<blockquote>
<p>Here, there is a split on whether the author is paid when the LLM studies the contents of the book.</p>
</blockquote>
<ul>
<li>GPT4: 5/ The way we measure the value of a book is changing, and the importance of “the amount that can be said that the LLM at hand cannot say” is becoming more important. This can be quantitatively assessed by a third party; payment to authors for LLMs learning book content will be an important discussion in the publishing industry in the future.<a href="./tags/future" class="tag-link internal alias" data-slug="tags/future">future</a> of publishing<a href="./tags/book" class="tag-link internal alias" data-slug="tags/book">book</a> value<a href="./tags/LLLM" class="tag-link internal alias" data-slug="tags/LLLM">LLLM</a> learning</li>
</ul>
</li>
<li>
<blockquote>
<p>If there is payment, the weight of the “payment received for the amount of contribution to LLM by becoming LLM’s study data” will be larger than the “profit from human readers buying” of the author’s income. Those who can create something new are safe.</p>
</blockquote>
<ul>
<li>GPT4: 6/ If author income is paid for “contributions to the LLM study data,” this will be more important than profits from human readers. Those who generate new knowledge and ideas will see a steady revenue stream from this change.<a href="./tags/future" class="tag-link internal alias" data-slug="tags/future">future</a> of publishing<a href="./tags/author" class="tag-link internal alias" data-slug="tags/author">author</a> income<a href="./tags/LLLM" class="tag-link internal alias" data-slug="tags/LLLM">LLLM</a> contributions<a href="./tags/contributing" class="tag-link internal alias" data-slug="tags/contributing">contributing</a> to AI</li>
</ul>
</li>
<li>
<blockquote>
<p>If LLMs can learn without payment, there will be no incentive for publishers or authors to publish. If this happens, the publishers will be wiped out, so I think they will lobby before it gets to this point. I am not sure if a good compromise can be found between the publishers and LLM or if it will be an all-out war between the two sides…I wonder if the LLM side will get into publishing and take market share…</p>
</blockquote>
<ul>
<li>GPT4: 7/ If LLMs can learn without payment, the publishing industry may lose incentives. Publishers may lobby, but results are uncertain; new competitive structure will emerge as the LLM side moves into publishing and takes market share.<a href="./tags/TheFutureofPublishing" class="tag-link internal alias" data-slug="tags/TheFutureofPublishing">TheFutureofPublishing</a><a href="./tags/LLMvsPublishers" class="tag-link internal alias" data-slug="tags/LLMvsPublishers">LLMvsPublishers</a></li>
</ul>
</li>
</ul>
<p>Rebuttal.<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/></p>
<ul>
<li>GPT4: 1/ While there will be demand for paper books for works that are sensitive and artistic in nature, books whose primary purpose is to convey information will not disappear. For example, in legal and academic fields, paper books will continue to be a reliable and solid medium.</li>
<li>GPT4: 2/ The assumption that the LLM’s contribution to the study data increases the author’s income is valid as long as the author is able to continuously generate new knowledge and ideas. However, creative talent is not always sustainable, and market and cultural changes may reduce authors’ incomes.</li>
<li>GPT4: 3/ It is unclear whether publishers will lobby and find a drop-off point or all-out war with LLMs, but the publishing industry has a long history and has responded to many technological innovations in the past. The publishing industry will seek ways to coexist and prosper with LLMs by developing new business models and cooperative relationships.</li>
</ul>
<img src="https://scrapbox.io/api/pages/nishio/nishio/icon" alt="nishio.icon" height="19.5"/>
- As for #1, &quot;creating credibility by being a paper book&quot; is included in the emotional value. That demand will remain.
- 2: We are not claiming that income will increase. There will be a decrease in income.
- 3: They will probably try to find a way to coexist. Whether it will succeed or not remains to be seen.
<p>I tried it manually this time, but it’s not bad to have LLM comment back on my thoughts like this, maybe I’ll make it a Twitter Bot. But I’m worried that the Twitter API and its behavior might be a bit of a mess for the time being. I think I’ll just use the script at hand.</p>
<blockquote>
<p>If LLMs can learn without payment, there will be no incentive for publishers or authors to publish. If this happens, the publishers will be wiped out, so I think they will lobby before it gets to this point. I am not sure if a good compromise can be found between the publishers and LLM or if it will be an all-out war between the two sides…I wonder if the LLM side will get into publishing and take market share…</p>
</blockquote>
<ul>
<li><a href="https://twitter.com/ukkaripon/status/1637051223147958273?s=20" class="external">@ukkaripon<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>
<ul>
<li>
<blockquote>
<p>Isn’t it possible to have a future where stray LLMs (which can be done cheaply) are abundantly created by learning only the results from LLMs that pay authors (which can be expensive in terms of money), and as a result, no money goes to authors?</p>
</blockquote>
</li>
</ul>
</li>
<li>@nishio
<ul>
<li>It is technically possible. I think it will be after the technology “can learn only the results of existing LLMs and create a comparable LLM” is established, but once that technology is established, OpenAI and others will not let people freely tap APIs like they do now. The future will come when they will only do B2B with tight contracts with big companies. It’s not about books…</li>
</ul>
</li>
<li>@ukkaripon Yes, that’s true.</li>
</ul>
<hr/>
<p>This page is auto-translated from <a href="https://scrapbox.io/nishio/%E5%87%BA%E7%89%88%E6%A5%AD%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E8%80%83%E5%AF%9F" class="external">/nishio/出版業についての考察<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I’m very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./Books-are-mass-produced" class="internal">Books are mass produced</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> © 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>