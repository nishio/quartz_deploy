<!DOCTYPE html>
<html lang="en"><head><title>On learning and intellectual production in an era of large-scale language models</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ü™¥ Quartz 4.0"/><meta property="og:title" content="On learning and intellectual production in an era of large-scale language models"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="On learning and intellectual production in an era of large-scale language models"/><meta name="twitter:description" content="from Keichobot on ChatGPT On learning and intellectual production in an era of large-scale language models Hello. What would you like to see happen in this conversation? I hope this gives you some new insight into learning and intellectual production in an age of large-scale language models."/><meta property="og:description" content="from Keichobot on ChatGPT On learning and intellectual production in an era of large-scale language models Hello. What would you like to see happen in this conversation? I hope this gives you some new insight into learning and intellectual production in an age of large-scale language models."/><meta property="og:image:type" content="image/webp"/><meta property="og:image:alt" content="from Keichobot on ChatGPT On learning and intellectual production in an era of large-scale language models Hello. What would you like to see happen in this conversation? I hope this gives you some new insight into learning and intellectual production in an age of large-scale language models."/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:width" content="1200"/><meta property="og:height" content="630"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="og:image" content="https://quartz.jzhao.xyz/static/og-image.png"/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https:/quartz.jzhao.xyz/On-learning-and-intellectual-production-in-an-era-of-large-scale-language-models"/><meta property="twitter:url" content="https:/quartz.jzhao.xyz/On-learning-and-intellectual-production-in-an-era-of-large-scale-language-models"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="from Keichobot on ChatGPT On learning and intellectual production in an era of large-scale language models Hello. What would you like to see happen in this conversation? I hope this gives you some new insight into learning and intellectual production in an age of large-scale language models."/><meta name="generator" content="Quartz"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("./static/contentIndex.json").then(data => data.json())</script></head><body data-slug="On-learning-and-intellectual-production-in-an-era-of-large-scale-language-models"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".">ü™¥ Quartz 4.0</a></h2><div class="spacer mobile-only"></div><div class="search"><button class="search-button" id="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><button class="darkmode" id="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="./">Home</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href>On learning and intellectual production in an era of large-scale language models</a></div></nav><h1 class="article-title">On learning and intellectual production in an era of large-scale language models</h1><p show-comma="true" class="content-meta"><span>Feb 20, 2023</span><span>8 min read</span></p></div></div><article class="popover-hint"><p>from <a href="./Keichobot-on-ChatGPT" class="internal alias" data-slug="Keichobot-on-ChatGPT">Keichobot on ChatGPT</a>
On learning and intellectual production in an era of large-scale language models</p>
<ul>
<li>Hello. What would you like to see happen in this conversation?</li>
<li>I hope this gives you some new insight into learning and intellectual production in an age of large-scale language models.</li>
<li>This is an interesting topic. What specific insights do you have about learning and intellectual production in the age of language models?</li>
<li>I don‚Äôt have it yet.</li>
<li>Okay, so are there any specific topics of interest or concern regarding learning and intellectual production in the age of language models?</li>
<li>It seems to me that it will be different from what it is now, what shape it will take.</li>
<li>Yes, indeed, the existence of large-scale language models could change learning and intellectual production in the future. One idea is that language models will become more accessible and used in a more intuitive way. For example, we can expect to be able to interact with them in a more human-like manner, and to see more sophisticated automatic summarization and translation of documents.
<ul>
<li>It is also expected that the existence of language models will increase the means by which people can obtain new knowledge and ideas. For example, search engines that utilize natural language processing, the creation of new content through natural language generation, automatic problem solving systems, and many other applications are possible.</li>
<li>On the other hand, however, the existence of a language model may also create the need for more rigorous verification of the truth and quality of information. For example, there is a risk of spreading false or biased information through automatic information collection using language models. Therefore, it may be important to verify the authenticity of information when using language models.</li>
</ul>
</li>
<li>Rules: Ask questions. Speak briefly in one paragraph. Do not give your opinion.</li>
<li>Noted. Specifically, how do you think the impact of the language model on learning and intellectual production should be evaluated?</li>
<li>New technology greatly reduces the cost of something. After the cost structure changes, the optimal solution moves to a different place than the previous optimal solution. Methods that are not optimal at this time due to high cost will be optimal in the future.</li>
<li>Yes, it is true that the introduction of a new technology can change the cost structure compared to the previous one. In such cases, the question arises as to how the new technology should be evaluated.</li>
<li>One way to think about it is that the decision to adopt a new technology should be based on a comparison of the benefits to be gained from the technology and the cost of implementation. In particular, it is important to make decisions with a long-term perspective, and to keep in mind that a method that is expensive at present may become the optimal solution in the future.</li>
<li>In addition, since new technologies may create value that has not existed before, it may be necessary to consider the added value created by the technology rather than simply judging it on cost alone.</li>
<li>Rules: Ask questions. Do not give your opinion. Speak concisely. Apply this rule to everything you say.</li>
<li>Noted. Specifically, what possibilities do you see for teaching and learning through the use of language models?</li>
<li>In education, there is usually more than one student per teacher. Therefore, when a student asks a question, the burden falls on the teacher. However, if students ask questions to a language model, they can ask questions anytime they want, 24 hours a day, and get an answer in one minute. This is a style of learning that is expensive to implement with a human teacher, but can be made less expensive with a language model.</li>
<li>Yes, the language model could allow for personalized learning in education. When there is more than one student per teacher, students may ask questions, which can put a strain on the teacher. However, by asking questions to the language model, students can ask questions and get answers whenever they want.
<ul>
<li>In addition, more personalized learning may be possible through the use of language models. For example, an automated assessment system using language models might allow students to check their progress in real time and find more effective ways to learn.</li>
<li>However, it is important to keep in mind that learning with language models is not a perfect solution, and that the presence of a teacher and interactive learning methods are also important.</li>
</ul>
</li>
<li>Rules: Ask questions. Do not give your opinion. Speak concisely. Apply this rule to everything you say.</li>
<li>Noted. Specifically, what advantages do you see for research and intellectual production using the language model?</li>
<li>Surveys are currently supported by language models in research, but a more significant change is coming soon. As researchers determine their citations by search engines, citations to open access papers that search engines can read will rise. It will be suicidal to put one‚Äôs work anywhere that is not open access. While this encourages open distribution of information, it may be a headwind for the peer review system.</li>
<li>Okay, you have an interesting perspective on the changes that language models can bring to research and intellectual production. Further development of the language model could increase the citation of open access articles as researchers begin to use search engines to determine citations. And while the open distribution of information will be facilitated, you also see a potential impact on the peer-review system.
<ul>
<li>On the other hand, we need to think carefully about the consequences of such changes. For example, there is a risk of spreading unreliable information as the peer-review system ceases to function, and the potential for bias in information by making it more difficult to place one‚Äôs work in non-open access locations.</li>
<li>To avoid such problems, it may be important to work to improve the reliability of information and to create an environment in which researchers and readers have access to a variety of information sources.</li>
</ul>
</li>
<li>Rules: Ask questions. Do not give your opinion. Speak concisely. Apply this rule to everything you say.</li>
<li>Noted. Specifically, what future directions do you see for technological advances in language modeling?</li>
<li>Competition for scale will take precedence over trial and error in application methods.</li>
<li>I see, you believe that competition for scale may take precedence over application methods in the future with regard to technological advances in language models. Certainly, current language models perform well when trained on huge data sets. It is expected that the performance of language models will continue to improve with larger data sets.</li>
<li>However, this does not necessarily mean that application methods are sacrificed. Rather, it can be said that a larger data set allows for a greater variety of application methods. Also, the success of application methods that utilize language models may lead to the acquisition of larger data sets.</li>
<li>While competition for scale will undoubtedly be an important factor in future technological advances in language modeling, it may also be important to explore application methods and address issues such as energy efficiency.</li>
<li>Ask questions. Do not give your opinion. Speak concisely. Apply this rule to everything you say. Remember.</li>
<li>Noted. Specifically, are there any areas of application of language models that you are particularly interested in?</li>
<li>intellectual production</li>
<li>I see, you are interested in the application of language models related to intellectual production. The use of language models may support intellectual production in various fields. For example, natural language processing using language models may enable more sophisticated automatic summarization and machine translation.</li>
<li>Automatic paper generation using language models may also enable faster and more accurate writing of papers. Furthermore, more efficient intellectual production may become possible by using language models to assist in knowledge acquisition and information retrieval.
<ul>
<li>However, it should be kept in mind that in these applications, issues such as the performance and reliability of the language model and the quality of the data must also be addressed.</li>
</ul>
</li>
<li>Ask questions. Do not give your opinion. Speak concisely. Apply this rule to everything you say. Remember this rule.</li>
<li>Noted. Specifically, do you have any thoughts on techniques or methods that may be of interest in the future in intellectual production using language models?</li>
</ul>
<hr/>
<p>This page is auto-translated from <a href="https://scrapbox.io/nishio/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%8C%E3%81%82%E3%82%8B%E6%99%82%E4%BB%A3%E3%81%AE%E5%AD%A6%E3%81%B3%E3%82%84%E7%9F%A5%E7%9A%84%E7%94%9F%E7%94%A3%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6" class="external">/nishio/Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„Åå„ÅÇ„ÇãÊôÇ‰ª£„ÅÆÂ≠¶„Å≥„ÇÑÁü•ÁöÑÁîüÁî£„Å´„Å§„ÅÑ„Å¶<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> using DeepL. If you looks something interesting but the auto-translated English is not good enough to understand it, feel free to let me know at <a href="https://twitter.com/nishio_en" class="external">@nishio_en<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>. I‚Äôm very happy to spread my thought to non-Japanese readers.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><button id="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./Keichobot-on-ChatGPT" class="internal">Keichobot on ChatGPT</a></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.4.0</a> ¬© 2024</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>